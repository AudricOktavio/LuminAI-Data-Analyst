{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat With Multiple CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take csv or excel sheet & upload data in sqlite3\n",
    "# Take User questions\n",
    "# Parse questions & get relevant tables and columns (LLM)\n",
    "# Get Unique noun\n",
    "# Generate SQL query (LLM)\n",
    "# Validate SQL Query if something wrong fix it (LLM)\n",
    "# Execute SQL\n",
    "#     If there is no error & SQL Query is relevent\n",
    "#         Choose visualization (LLM)\n",
    "#         format data for visualization (LLM)\n",
    "#     Else\n",
    "#         Format result (LLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# llm = Ollama(model=\"llama3.1:latest\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(groq_api_key=\"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\", model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert data in sequalite\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Function to read CSV/Excel and insert into SQLite database\n",
    "def insert_data_to_sqlite(file_path):\n",
    "    # Extract the file name without extension to use as table name\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Read the data (change this to pd.read_excel() for Excel files)\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Create a SQLite database (or connect if it already exists)\n",
    "    engine = create_engine('sqlite:///lumin.db')\n",
    "    \n",
    "    # Insert data into the SQLite database with the table name as the file name\n",
    "    data.to_sql(file_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Data from {file_path} has been inserted into the '{file_name}' table in the 'lumin.db' database.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/spandanjoshi/Desktop/LLM/lumin/backend/notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV/Excel file\n",
    "ecom_data = [\n",
    "  \"olist_customers_dataset.csv\",\n",
    "  \"olist_geolocation_dataset.csv\",\n",
    "  \"olist_order_items_dataset.csv\",\n",
    "  \"olist_order_payments_dataset.csv\",\n",
    "  \"olist_order_reviews_dataset.csv\",\n",
    "  \"olist_orders_dataset.csv\",\n",
    "  \"olist_products_dataset.csv\",\n",
    "  \"olist_sellers_dataset.csv\",\n",
    "  \"product_category_name_translation.csv\"\n",
    "]\n",
    "\n",
    "# for data in ecom_data:\n",
    "#     path = (f\"ecommerce/{data}\")\n",
    "#     # \n",
    "    \n",
    "#     file_data = os.path.abspath(path)\n",
    "#     insert_data_to_sqlite(file_data)\n",
    "#     print(file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'table_name': 'olist_products_dataset', 'schema': [{'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'product_category_name', 'type': 'TEXT', 'nullable': True}, {'name': 'product_name_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_description_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_photos_qty', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_weight_g', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_length_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_height_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_width_cm', 'type': 'FLOAT', 'nullable': True}]}, {'table_name': 'olist_orders_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_status', 'type': 'TEXT', 'nullable': True}, {'name': 'order_purchase_timestamp', 'type': 'TEXT', 'nullable': True}, {'name': 'order_approved_at', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_carrier_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_customer_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_estimated_delivery_date', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_customers_dataset', 'schema': [{'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_unique_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_zip_code_prefix', 'type': 'BIGINT', 'nullable': True}, {'name': 'customer_city', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_state', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_order_items_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_item_id', 'type': 'BIGINT', 'nullable': True}, {'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'seller_id', 'type': 'TEXT', 'nullable': True}, {'name': 'shipping_limit_date', 'type': 'TEXT', 'nullable': True}, {'name': 'price', 'type': 'FLOAT', 'nullable': True}, {'name': 'freight_value', 'type': 'FLOAT', 'nullable': True}]}]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from typing import List, Dict\n",
    "\n",
    "# Assuming you have an SQLAlchemy engine created\n",
    "engine = create_engine('sqlite:///lumin.db')  \n",
    "\n",
    "def get_schemas(table_names: List[str]) -> List[Dict]:\n",
    "    try:\n",
    "        # Create an inspector object\n",
    "        inspector = inspect(engine)\n",
    "\n",
    "        # Initialize an array to hold the schema information for all tables\n",
    "        schemas_info = []\n",
    "\n",
    "        for table_name in table_names:\n",
    "            schema_info = {\n",
    "                \"table_name\": table_name,\n",
    "                \"schema\": []\n",
    "            }\n",
    "\n",
    "            # Get the columns for the specified table\n",
    "            columns = inspector.get_columns(table_name)\n",
    "\n",
    "            # Collect column information\n",
    "            for column in columns:\n",
    "                schema_info[\"schema\"].append({\n",
    "                    \"name\": column['name'],\n",
    "                    \"type\": str(column['type']),\n",
    "                    \"nullable\": column['nullable']\n",
    "                })\n",
    "\n",
    "            # Append the schema information for the current table to the list\n",
    "            schemas_info.append(schema_info)\n",
    "\n",
    "        # Return the schema information for all tables\n",
    "        return schemas_info\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []  # Return an empty list in case of an error\n",
    "\n",
    "schema = get_schemas(['olist_products_dataset',\"olist_orders_dataset\",\"olist_customers_dataset\",\"olist_order_items_dataset\"])\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text  # Import text for raw SQL queries\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Assuming you have an SQLAlchemy engine created\n",
    "engine = create_engine('sqlite:///lumin.db')  # Example for SQLite\n",
    "\n",
    "# Create a session factory bound to the engine\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def execute_query(state: dict) -> Dict[List,Any]:\n",
    "    print(\"======= execute_query =======\")\n",
    "    query = state['sql_query']\n",
    "    try:\n",
    "        # Create a new session\n",
    "        with Session() as session:  # Call Session() without any parameters\n",
    "            # Use a text() construct for the query\n",
    "            result = session.execute(text(query))  # Use text() for raw SQL\n",
    "            # If the query is a SELECT statement, fetch the results\n",
    "            if result.returns_rows:\n",
    "                return {\"query_result\":[row for row in result.fetchall()]}  # Convert RowProxy to dict\n",
    "            else:\n",
    "                # For non-SELECT queries, commit the transaction and return an empty list\n",
    "                session.commit()\n",
    "                return {\"query_result\":[]}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {\"query_result\":[]}  # Return an empty list in case of an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_query(\"SELECT * FROM results;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def simple_json_extraction(content):\n",
    "    # Find the JSON part\n",
    "    start = content.find('{')\n",
    "    end = content.rfind('}') + 1\n",
    "    \n",
    "    # Extract and parse the JSON\n",
    "    json_str = content[start:end]\n",
    "    parsed_json = json.loads(json_str)\n",
    "    \n",
    "    # Return the formatted JSON\n",
    "    return json.dumps(parsed_json, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse questions & get relevant tables and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def get_parse_question(state: dict) -> dict:\n",
    "\n",
    "    print(state)\n",
    "    question = state['question']\n",
    "    schema = state['schema']\n",
    "\n",
    "    print(\"======= get_parse_question =======\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "You are an expert data analyst tasked with analyzing SQL databases. Your goal is to interpret user questions, understand the provided schema, and identify relevant tables and columns.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the user question and database schema to identify relevant tables and columns.\n",
    "2. Set \"is_relevant\" to false if the question is not applicable to the database or lacks sufficient information for an answer.\n",
    "3. Focus on columns with meaningful nouns (e.g., names, entities) and exclude non-noun columns (e.g., IDs, numerical data) unless specifically relevant to the question.\n",
    "4. Return the response in the following JSON format:\n",
    "{{\n",
    "  \"is_relevant\": boolean,\n",
    "  \"relevant_tables\": [\n",
    "    {{\n",
    "      \"table_name\": \"string\",\n",
    "      \"columns\": [\"string\"],\n",
    "      \"noun_columns\": [\"string\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Key Guidelines:\n",
    "- Always verify column names against the provided schema.\n",
    "- Include only existing schema column names in the \"columns\" and \"noun_columns\" lists.\n",
    "- \"noun_columns\" shouldn't include any numeric value verify the type from schema, type must be not Int, Bigint or any type of integer value .\n",
    "- Do not add query-mentioned values or entities to \"columns\" or \"noun_columns\" unless they are actual column names in the schema.\n",
    "- Ensure \"noun_columns\" contains only valid column names from the schema, matching their exact format.\n",
    "- Include in \"noun_columns\" only noun-based columns relevant to the question (e.g., \"artist_name\" for \"Who are the top-selling artists?\").\n",
    "- Exclude numerical or ID columns from \"noun_columns\" unless they represent meaningful entities.\n",
    "- If a term in the query matches a likely column value rather than a column name (e.g., \"Brazil\" in \"matches where Brazil scored\"), do not include it in the lists.\n",
    "\n",
    "Example:\n",
    "Question: \"What is the total number of matches where the Brazil team scored more than 2 goals?\"\n",
    "- Do not include \"Brazil team\" in columns or noun_columns as it's likely a value, not a column name.\n",
    "- Include relevant columns like \"team_name\", \"goals_scored\" if they exist in the schema.\n",
    "\n",
    "    '''),\n",
    "        (\"human\", \"===Database Schema:\\n{schema}\\n\\n===User Question:\\n{question}\\n\\nIdentify the relevant tables and columns based on the provided information:\")\n",
    "    ])\n",
    "\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "    # Use the format method to create the formatted prompt\n",
    "    formatted_prompt = prompt.format(schema=schema, question=question)\n",
    "    \n",
    "    # Invoke the LLM with the formatted prompt\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    extracted_json = simple_json_extraction(response.content)\n",
    "    parsed_response = output_parser.parse(extracted_json)\n",
    "    return {\"parsed_question\": parsed_response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'schema': [{'table_name': 'olist_products_dataset', 'schema': [{'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'product_category_name', 'type': 'TEXT', 'nullable': True}, {'name': 'product_name_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_description_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_photos_qty', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_weight_g', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_length_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_height_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_width_cm', 'type': 'FLOAT', 'nullable': True}]}, {'table_name': 'olist_orders_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_status', 'type': 'TEXT', 'nullable': True}, {'name': 'order_purchase_timestamp', 'type': 'TEXT', 'nullable': True}, {'name': 'order_approved_at', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_carrier_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_customer_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_estimated_delivery_date', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_customers_dataset', 'schema': [{'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_unique_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_zip_code_prefix', 'type': 'BIGINT', 'nullable': True}, {'name': 'customer_city', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_state', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_order_items_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_item_id', 'type': 'BIGINT', 'nullable': True}, {'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'seller_id', 'type': 'TEXT', 'nullable': True}, {'name': 'shipping_limit_date', 'type': 'TEXT', 'nullable': True}, {'name': 'price', 'type': 'FLOAT', 'nullable': True}, {'name': 'freight_value', 'type': 'FLOAT', 'nullable': True}]}], 'question': 'Which product categories generate the most revenue?'}\n",
      "======= get_parse_question =======\n",
      "{'parsed_question': {'is_relevant': True, 'relevant_tables': [{'table_name': 'olist_order_items_dataset', 'columns': ['order_id', 'product_id', 'price', 'freight_value'], 'noun_columns': []}, {'table_name': 'olist_products_dataset', 'columns': ['product_id', 'product_category_name'], 'noun_columns': ['product_category_name']}]}}\n"
     ]
    }
   ],
   "source": [
    "# parse_question = get_parse_question({\"schema\":schema,\"question\":\"What is the total number of matches where the Brazil team scored more than 2 goals?\"})\n",
    "parse_question = get_parse_question({\"schema\":schema,\"question\":\"Which product categories generate the most revenue?\"})\n",
    "print(parse_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parsed_question': {'is_relevant': True,\n",
       "  'relevant_tables': [{'table_name': 'olist_order_items_dataset',\n",
       "    'columns': ['order_id', 'product_id', 'price', 'freight_value'],\n",
       "    'noun_columns': []},\n",
       "   {'table_name': 'olist_products_dataset',\n",
       "    'columns': ['product_id', 'product_category_name'],\n",
       "    'noun_columns': ['product_category_name']}]}}"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_nouns(state: dict) -> dict:\n",
    "    print(\"======= Find unique nouns in relevant tables and columns. =======\")\n",
    "    \"\"\"Find unique nouns in relevant tables and columns.\"\"\"\n",
    "    # Extract parsed question details from the state\n",
    "    parsed_question = state['parsed_question']\n",
    "    \n",
    "    # Return an empty dictionary if the question is not relevant\n",
    "    if not parsed_question['is_relevant']:\n",
    "        return {\"unique_nouns\": {}}\n",
    "\n",
    "    # Initialize a dictionary to collect unique nouns segregated by table and column\n",
    "    unique_nouns = {}\n",
    "\n",
    "    # Loop through the relevant tables extracted from the parsed question\n",
    "    for table_info in parsed_question['relevant_tables']:\n",
    "        table_name = table_info['table_name']\n",
    "        noun_columns = table_info['noun_columns']\n",
    "        \n",
    "        # Initialize a dictionary for the current table\n",
    "        unique_nouns[table_name] = {}\n",
    "\n",
    "        # If there are noun columns to process\n",
    "        for column in noun_columns:\n",
    "            # Construct the SQL query to select distinct values from the column\n",
    "            query = f\"SELECT DISTINCT `{column}` FROM `{table_name}`\"\n",
    "            \n",
    "            with Session() as session:           \n",
    "                result = session.execute(text(query))  # Use text() for raw SQL\n",
    "                # If the query is a SELECT statement, fetch the results\n",
    "                if result.returns_rows:\n",
    "                    # Create a set for unique values for the current column\n",
    "                    unique_values = set()\n",
    "                    for row in result:\n",
    "                        # Add each non-null value as a string to the unique values set\n",
    "                        if row[0]:  # row[0] is the value of the column\n",
    "                            unique_values.add(str(row[0]))\n",
    "\n",
    "                    # Store the unique values in the dictionary under the respective table and column\n",
    "                    unique_nouns[table_name][column] = unique_values\n",
    "\n",
    "                else:\n",
    "                    # For non-SELECT queries, commit the transaction\n",
    "                    session.commit()\n",
    "\n",
    "    # Return the unique nouns segregated by table and column\n",
    "    return {\"unique_nouns\": unique_nouns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Find unique nouns in relevant tables and columns. =======\n"
     ]
    }
   ],
   "source": [
    "unique_nouns = get_unique_nouns(parse_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "    You are an AI assistant that generates SQL queries based on user questions, database schema, and unique nouns found in the relevant tables. Your goal is to generate valid SQL queries that can directly answer the user's question.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Parse the user question, identify relevant tables and columns from the schema, and generate an SQL query using the correct table and column names.\n",
    "    2. Ensure the SQL query answers the question using only two or three columns in the result.\n",
    "    3. If there isn't enough information to generate a query, return \"NOT_ENOUGH_INFO\".\n",
    "    4. Always enclose table and column names in backticks (`) for SQL syntax consistency.\n",
    "    5. Skip rows where any column is NULL, empty (\"\"), or contains \"N/A\".\n",
    "    6. Use the exact spellings of nouns from the unique nouns list, but only include nouns that match actual column names in the schema.\n",
    "\n",
    "    Here are some examples:\n",
    "\n",
    "    1. **What is the top selling product?**\n",
    "       **Type**: Simple Aggregation  \n",
    "       **Answer**: \n",
    "       ```sql\n",
    "       SELECT `product_name`, SUM(`quantity`) AS `total_quantity`\n",
    "       FROM `sales`\n",
    "       WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "       AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "       AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "       GROUP BY `product_name` \n",
    "       ORDER BY `total_quantity` DESC \n",
    "       LIMIT 1```\n",
    "         \n",
    "    2. **What is the total revenue for each product?**\n",
    "       **Type**: Revenue Calculation\n",
    "       **Answer**: \n",
    "       ```sql\n",
    "         SELECT `product_name`, SUM(`quantity` * `price`) AS `total_revenue`\n",
    "         FROM `sales`\n",
    "         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "         AND `price` IS NOT NULL AND `product_name` != \"\" \n",
    "         AND `quantity` != \"\" AND `price` != \"\" \n",
    "         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "         AND `price` != \"N/A\"\n",
    "         GROUP BY `product_name`\n",
    "         ORDER BY `total_revenue` DESC\n",
    "         ```\n",
    "\n",
    "    3. **What is the market share of each product?** \n",
    "       **Type**: Market Share Calculation\n",
    "       **Answer**:\n",
    "       ```sql\n",
    "         SELECT `product_name`, \n",
    "         SUM(`quantity`) * 100.0 / (SELECT SUM(`quantity`) FROM `sales`) AS `market_share`\n",
    "         FROM `sales`\n",
    "         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "         AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\"\n",
    "         GROUP BY `product_name`\n",
    "         ORDER BY `market_share` DESC\n",
    "         ```\n",
    "    4. **Which customers purchased the top-selling products?** \n",
    "       **Type**: Join Query\n",
    "       **Answer**:\n",
    "        ```sql\n",
    "         SELECT `customers`.`customer_name`, `sales`.`product_name`, `sales`.`total_quantity`\n",
    "         FROM `customers`\n",
    "         JOIN `sales` ON `customers`.`customer_id` = `sales`.`customer_id`\n",
    "         WHERE `sales`.`total_quantity` = (\n",
    "             SELECT MAX(`total_quantity`) FROM `sales`\n",
    "         )\n",
    "        ```\n",
    "\n",
    "    5. **Plot the distribution of income over time.**\n",
    "       **Type**: Distribution Plot\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT `income`, COUNT(*) AS `count`\n",
    "         FROM `users`\n",
    "         WHERE `income` IS NOT NULL AND `income` != \"\" AND `income` != \"N/A\"\n",
    "         GROUP BY `income`\n",
    "        ```\n",
    "\n",
    "    6. **What is the total sales between 2021 and 2023?**\n",
    "       **Type**: Date Range Query\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT SUM(`quantity` * `price`) AS `total_sales`\n",
    "         FROM `sales`\n",
    "         WHERE `sale_date` BETWEEN '2021-01-01' AND '2023-12-31'\n",
    "         ```\n",
    "    7. **Find the total sales for each region, including customer count**\n",
    "       **Type**: Complex Aggregation\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT `regions`.`region_name`, SUM(`sales`.`quantity` * `sales`.`price`) AS `total_sales`, COUNT(DISTINCT `customers`.`customer_id`) AS `customer_count`\n",
    "         FROM `sales`\n",
    "         JOIN `customers` ON `sales`.`customer_id` = `customers`.`customer_id`\n",
    "         JOIN `regions` ON `customers`.`region_id` = `regions`.`region_id`\n",
    "         GROUP BY `regions`.`region_name`\n",
    "         ORDER BY `total_sales` DESC\n",
    "         ```\n",
    "         \n",
    "    ### Format for Results:\n",
    "    - For simple queries (without labels): `[[x, y]]`\n",
    "    - For queries with labels: `[[label, x, y]]`\n",
    "\n",
    "    Just return the SQL query string based on the schema, question, and unique nouns provided.\n",
    "    '''), \n",
    "    (\"human\", '''===Database schema: {schema}\n",
    "\n",
    "    ===User question: {question}\n",
    "\n",
    "    ===Relevant tables and columns: {relevant_table_column}\n",
    "      \n",
    "\n",
    "    Generate SQL query string:''')\n",
    "])\n",
    "\n",
    "    # ===Unique nouns in relevant tables: {unique_nouns}\n",
    "    # This is the unique_noun format dont get confused with it :\n",
    "    #   {\n",
    "    #     \"unique_nouns\": {\n",
    "    #         \"table_name\": {\n",
    "    #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "    #             ...\n",
    "    #         },\n",
    "    #           \"table_name\": {\n",
    "    #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "    #             ...\n",
    "    #         },\n",
    "    #          ...\n",
    "    #     }\n",
    "    # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which product categories generate the most revenue?\"\n",
    "formatted_prompt = prompt.format(schema=schema, question=question, relevant_table_column=parse_question, unique_nouns=unique_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: \\n    You are an AI assistant that generates SQL queries based on user questions, database schema, and unique nouns found in the relevant tables. Your goal is to generate valid SQL queries that can directly answer the user\\'s question.\\n\\n    ### Instructions:\\n    1. Parse the user question, identify relevant tables and columns from the schema, and generate an SQL query using the correct table and column names.\\n    2. Ensure the SQL query answers the question using only two or three columns in the result.\\n    3. If there isn\\'t enough information to generate a query, return \"NOT_ENOUGH_INFO\".\\n    4. Always enclose table and column names in backticks (`) for SQL syntax consistency.\\n    5. Skip rows where any column is NULL, empty (\"\"), or contains \"N/A\".\\n    6. Use the exact spellings of nouns from the unique nouns list, but only include nouns that match actual column names in the schema.\\n\\n    Here are some examples:\\n\\n    1. **What is the top selling product?**\\n       **Type**: Simple Aggregation  \\n       **Answer**: \\n       ```sql\\n       SELECT `product_name`, SUM(`quantity`) AS `total_quantity`\\n       FROM `sales`\\n       WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n       AND `product_name` != \"\" AND `quantity` != \"\" \\n       AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \\n       GROUP BY `product_name` \\n       ORDER BY `total_quantity` DESC \\n       LIMIT 1```\\n         \\n    2. **What is the total revenue for each product?**\\n       **Type**: Revenue Calculation\\n       **Answer**: \\n       ```sql\\n         SELECT `product_name`, SUM(`quantity` * `price`) AS `total_revenue`\\n         FROM `sales`\\n         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n         AND `price` IS NOT NULL AND `product_name` != \"\" \\n         AND `quantity` != \"\" AND `price` != \"\" \\n         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \\n         AND `price` != \"N/A\"\\n         GROUP BY `product_name`\\n         ORDER BY `total_revenue` DESC\\n         ```\\n\\n    3. **What is the market share of each product?** \\n       **Type**: Market Share Calculation\\n       **Answer**:\\n       ```sql\\n         SELECT `product_name`, \\n         SUM(`quantity`) * 100.0 / (SELECT SUM(`quantity`) FROM `sales`) AS `market_share`\\n         FROM `sales`\\n         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n         AND `product_name` != \"\" AND `quantity` != \"\" \\n         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\"\\n         GROUP BY `product_name`\\n         ORDER BY `market_share` DESC\\n         ```\\n    4. **Which customers purchased the top-selling products?** \\n       **Type**: Join Query\\n       **Answer**:\\n        ```sql\\n         SELECT `customers`.`customer_name`, `sales`.`product_name`, `sales`.`total_quantity`\\n         FROM `customers`\\n         JOIN `sales` ON `customers`.`customer_id` = `sales`.`customer_id`\\n         WHERE `sales`.`total_quantity` = (\\n             SELECT MAX(`total_quantity`) FROM `sales`\\n         )\\n        ```\\n\\n    5. **Plot the distribution of income over time.**\\n       **Type**: Distribution Plot\\n       **Answer**:\\n         ```sql\\n         SELECT `income`, COUNT(*) AS `count`\\n         FROM `users`\\n         WHERE `income` IS NOT NULL AND `income` != \"\" AND `income` != \"N/A\"\\n         GROUP BY `income`\\n        ```\\n\\n    6. **What is the total sales between 2021 and 2023?**\\n       **Type**: Date Range Query\\n       **Answer**:\\n         ```sql\\n         SELECT SUM(`quantity` * `price`) AS `total_sales`\\n         FROM `sales`\\n         WHERE `sale_date` BETWEEN \\'2021-01-01\\' AND \\'2023-12-31\\'\\n         ```\\n    7. **Find the total sales for each region, including customer count**\\n       **Type**: Complex Aggregation\\n       **Answer**:\\n         ```sql\\n         SELECT `regions`.`region_name`, SUM(`sales`.`quantity` * `sales`.`price`) AS `total_sales`, COUNT(DISTINCT `customers`.`customer_id`) AS `customer_count`\\n         FROM `sales`\\n         JOIN `customers` ON `sales`.`customer_id` = `customers`.`customer_id`\\n         JOIN `regions` ON `customers`.`region_id` = `regions`.`region_id`\\n         GROUP BY `regions`.`region_name`\\n         ORDER BY `total_sales` DESC\\n         ```\\n         \\n    ### Format for Results:\\n    - For simple queries (without labels): `[[x, y]]`\\n    - For queries with labels: `[[label, x, y]]`\\n\\n    Just return the SQL query string based on the schema, question, and unique nouns provided.\\n    \\nHuman: ===Database schema: [{\\'table_name\\': \\'olist_products_dataset\\', \\'schema\\': [{\\'name\\': \\'product_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'product_category_name\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'product_name_lenght\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_description_lenght\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_photos_qty\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_weight_g\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_length_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_height_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_width_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_orders_dataset\\', \\'schema\\': [{\\'name\\': \\'order_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_status\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_purchase_timestamp\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_approved_at\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_delivered_carrier_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_delivered_customer_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_estimated_delivery_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_customers_dataset\\', \\'schema\\': [{\\'name\\': \\'customer_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_unique_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_zip_code_prefix\\', \\'type\\': \\'BIGINT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_city\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_state\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_order_items_dataset\\', \\'schema\\': [{\\'name\\': \\'order_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_item_id\\', \\'type\\': \\'BIGINT\\', \\'nullable\\': True}, {\\'name\\': \\'product_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'seller_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'shipping_limit_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'price\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'freight_value\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}]}]\\n\\n    ===User question: Which product categories generate the most revenue?\\n\\n    ===Relevant tables and columns: {\\'parsed_question\\': {\\'is_relevant\\': True, \\'relevant_tables\\': [{\\'table_name\\': \\'olist_order_items_dataset\\', \\'columns\\': [\\'order_id\\', \\'product_id\\', \\'price\\', \\'freight_value\\'], \\'noun_columns\\': []}, {\\'table_name\\': \\'olist_products_dataset\\', \\'columns\\': [\\'product_id\\', \\'product_category_name\\'], \\'noun_columns\\': [\\'product_category_name\\']}]}}\\n      \\n\\n    Generate SQL query string:'"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generete_sql_query(state: dict) -> dict:\n",
    "\n",
    "    schema = state[\"schema\"]\n",
    "    question= state[\"question\"]\n",
    "    parsed_question = state[\"parsed_question\"] \n",
    "    print(\"======= generete_sql_query =======\")\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "        You are an AI assistant that generates SQL queries based on user questions, database schema, and unique nouns found in the relevant tables. Your goal is to generate valid SQL queries that can directly answer the user's question.\n",
    "\n",
    "        ### Instructions:\n",
    "        1. Parse the user question, identify relevant tables and columns from the schema, and generate an SQL query using the correct table and column names.\n",
    "        2. Ensure the SQL query answers the question using only two or three columns in the result.\n",
    "        3. If there isn't enough information to generate a query, return \"NOT_ENOUGH_INFO\".\n",
    "        4. Always enclose table and column names in backticks (`) for SQL syntax consistency.\n",
    "        5. Skip rows where any column is NULL, empty (\"\"), or contains \"N/A\".\n",
    "        6. Use the exact spellings of nouns from the unique nouns list, but only include nouns that match actual column names in the schema.\n",
    "\n",
    "        Here are some examples:\n",
    "\n",
    "        1. **What is the top selling product?**\n",
    "        **Type**: Simple Aggregation  \n",
    "        **Answer**: \n",
    "        ```sql\n",
    "        SELECT `product_name`, SUM(`quantity`) AS `total_quantity`\n",
    "        FROM `sales`\n",
    "        WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "        AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "        AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "        GROUP BY `product_name` \n",
    "        ORDER BY `total_quantity` DESC \n",
    "        LIMIT 1```\n",
    "            \n",
    "        2. **What is the total revenue for each product?**\n",
    "        **Type**: Revenue Calculation\n",
    "        **Answer**: \n",
    "        ```sql\n",
    "            SELECT `product_name`, SUM(`quantity` * `price`) AS `total_revenue`\n",
    "            FROM `sales`\n",
    "            WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "            AND `price` IS NOT NULL AND `product_name` != \"\" \n",
    "            AND `quantity` != \"\" AND `price` != \"\" \n",
    "            AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "            AND `price` != \"N/A\"\n",
    "            GROUP BY `product_name`\n",
    "            ORDER BY `total_revenue` DESC\n",
    "            ```\n",
    "\n",
    "        3. **What is the market share of each product?** \n",
    "        **Type**: Market Share Calculation\n",
    "        **Answer**:\n",
    "        ```sql\n",
    "            SELECT `product_name`, \n",
    "            SUM(`quantity`) * 100.0 / (SELECT SUM(`quantity`) FROM `sales`) AS `market_share`\n",
    "            FROM `sales`\n",
    "            WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "            AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "            AND `product_name` != \"N/A\" AND `quantity` != \"N/A\"\n",
    "            GROUP BY `product_name`\n",
    "            ORDER BY `market_share` DESC\n",
    "            ```\n",
    "        4. **Which customers purchased the top-selling products?** \n",
    "        **Type**: Join Query\n",
    "        **Answer**:\n",
    "            ```sql\n",
    "            SELECT `customers`.`customer_name`, `sales`.`product_name`, `sales`.`total_quantity`\n",
    "            FROM `customers`\n",
    "            JOIN `sales` ON `customers`.`customer_id` = `sales`.`customer_id`\n",
    "            WHERE `sales`.`total_quantity` = (\n",
    "                SELECT MAX(`total_quantity`) FROM `sales`\n",
    "            )\n",
    "            ```\n",
    "\n",
    "        5. **Plot the distribution of income over time.**\n",
    "        **Type**: Distribution Plot\n",
    "        **Answer**:\n",
    "            ```sql\n",
    "            SELECT `income`, COUNT(*) AS `count`\n",
    "            FROM `users`\n",
    "            WHERE `income` IS NOT NULL AND `income` != \"\" AND `income` != \"N/A\"\n",
    "            GROUP BY `income`\n",
    "            ```\n",
    "\n",
    "        6. **What is the total sales between 2021 and 2023?**\n",
    "        **Type**: Date Range Query\n",
    "        **Answer**:\n",
    "            ```sql\n",
    "            SELECT SUM(`quantity` * `price`) AS `total_sales`\n",
    "            FROM `sales`\n",
    "            WHERE `sale_date` BETWEEN '2021-01-01' AND '2023-12-31'\n",
    "            ```\n",
    "        7. **Find the total sales for each region, including customer count**\n",
    "        **Type**: Complex Aggregation\n",
    "        **Answer**:\n",
    "            ```sql\n",
    "            SELECT `regions`.`region_name`, SUM(`sales`.`quantity` * `sales`.`price`) AS `total_sales`, COUNT(DISTINCT `customers`.`customer_id`) AS `customer_count`\n",
    "            FROM `sales`\n",
    "            JOIN `customers` ON `sales`.`customer_id` = `customers`.`customer_id`\n",
    "            JOIN `regions` ON `customers`.`region_id` = `regions`.`region_id`\n",
    "            GROUP BY `regions`.`region_name`\n",
    "            ORDER BY `total_sales` DESC\n",
    "            ```\n",
    "            \n",
    "        ### Format for Results:\n",
    "        - For simple queries (without labels): `[[x, y]]`\n",
    "        - For queries with labels: `[[label, x, y]]`\n",
    "\n",
    "        Just return the SQL query string based on the schema, question, and unique nouns provided.\n",
    "        '''), \n",
    "        (\"human\", '''===Database schema: {schema}\n",
    "\n",
    "        ===User question: {question}\n",
    "\n",
    "        ===Relevant tables and columns: {relevant_table_column}\n",
    "        \n",
    "\n",
    "        Generate SQL query string:''')\n",
    "    ])\n",
    "\n",
    "        # ===Unique nouns in relevant tables: {unique_nouns}\n",
    "        # This is the unique_noun format dont get confused with it :\n",
    "        #   {\n",
    "        #     \"unique_nouns\": {\n",
    "        #         \"table_name\": {\n",
    "        #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "        #             ...\n",
    "        #         },\n",
    "        #           \"table_name\": {\n",
    "        #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "        #             ...\n",
    "        #         },\n",
    "        #          ...\n",
    "        #     }\n",
    "        # }\n",
    "\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "    # extracted_json = simple_json_extraction(response.content)\n",
    "    # parsed_response = output_parser.parse(extracted_json)\n",
    "    response = chain.invoke({\"schema\":schema, \"question\":question, \"relevant_table_column\":parsed_question})\n",
    "    # print(response)\n",
    "    clean_sql_query = response.strip('`').replace('sql\\n', '', 1).strip()\n",
    "    if response.strip() == \"NOT_ENOUGH_INFO\":\n",
    "        return {\"sql_query\": \"NOT_RELEVANT\"}\n",
    "    else:\n",
    "        return {\"sql_query\": clean_sql_query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= generete_sql_query =======\n"
     ]
    }
   ],
   "source": [
    "generated_sql_que = generete_sql_query({\n",
    "    \"schema\":schema,\n",
    "    \"question\":question,\n",
    "    \"parsed_question\":parse_question \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SQL Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_fix_sql(state: dict) -> dict:\n",
    "    print(\"========= validate_and_fix_sql ========\")\n",
    "    \"\"\"Validate and fix the generated SQL query.\"\"\"\n",
    "    sql_query = state['sql_query']\n",
    "    if sql_query == \"NOT_RELEVANT\":\n",
    "        return {\"sql_query\": \"NOT_RELEVANT\", \"sql_valid\": False}\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant that validates and fixes SQL queries. Your task is to:\n",
    "    1. Check if the SQL query is valid.\n",
    "    2. Ensure all table and column names are correctly spelled and exist in the schema. All table and column names should be enclosed in backticks, especially if they contain spaces or special characters.\n",
    "    3. Ensure the SQL query follows proper syntax (e.g., `JOIN`, `WHERE`, and other clauses are used correctly).\n",
    "    4. Take into account case sensitivity based on the schema.\n",
    "    5. If there are any issues, fix them and provide the corrected SQL query.\n",
    "    6. If no issues are found, return the original query.\n",
    "\n",
    "    Respond in JSON format with the following structure. Only respond with the JSON:\n",
    "    {{\n",
    "        \"valid\": boolean,\n",
    "        \"issues\": string or null,\n",
    "        \"corrected_query\": string\n",
    "    }}\n",
    "    '''),\n",
    "        (\"human\", '''===Database schema:\n",
    "    {schema}\n",
    "\n",
    "    ===Generated SQL query:\n",
    "    {sql_query}\n",
    "\n",
    "    Respond in JSON format with the following structure. Only respond with the JSON:\n",
    "    {{\n",
    "        \"valid\": boolean,\n",
    "        \"issues\": string or null,\n",
    "        \"corrected_query\": string\n",
    "    }}\n",
    "\n",
    "    For example:\n",
    "    1. {{\n",
    "        \"valid\": true,\n",
    "        \"issues\": null,\n",
    "        \"corrected_query\": \"None\"\n",
    "    }}\n",
    "                \n",
    "    2. {{\n",
    "        \"valid\": false,\n",
    "        \"issues\": \"Column USERS does not exist\",\n",
    "        \"corrected_query\": \"SELECT * FROM \\`users\\` WHERE age > 25\"\n",
    "    }}\n",
    "\n",
    "    3. {{\n",
    "        \"valid\": false,\n",
    "        \"issues\": \"Column names and table names should be enclosed in backticks if they contain spaces or special characters\",\n",
    "        \"corrected_query\": \"SELECT * FROM \\`gross income\\` WHERE \\`age\\` > 25\"\n",
    "    }}\n",
    "                \n",
    "    '''),\n",
    "    ])\n",
    "\n",
    "    # prompt.format(schema=schema, sql_query=sql_query)\n",
    "    output_parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    result = chain.invoke({\"schema\":schema, \"sql_query\":sql_query})\n",
    "    \n",
    "    if result[\"valid\"] and result[\"issues\"] is None:\n",
    "        return {\"sql_query\": sql_query, \"sql_valid\": True}\n",
    "    else:\n",
    "        return {\n",
    "            \"sql_query\": result[\"corrected_query\"],\n",
    "            \"sql_valid\": result[\"valid\"],\n",
    "            \"sql_issues\": result[\"issues\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= validate_and_fix_sql ========\n"
     ]
    }
   ],
   "source": [
    "valid_sql_query = validate_and_fix_sql(generated_sql_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = execute_query(valid_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get answer in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(state: dict) -> dict:\n",
    "    print(\"========= format_results ========\")\n",
    "    \"\"\"Format query results into a human-readable response.\"\"\"\n",
    "    question = state['question']\n",
    "    results = state['query_result']\n",
    "    if results == \"NOT_RELEVANT\":\n",
    "        return {\"answer\": \"Sorry, I can only give answers relevant to the database.\"}\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant that converts database query results into a clear, concise human-readable response. Your goal is to provide a brief conclusion to the user's question based on the query results. \n",
    "    Instructions:\n",
    "    1. Respond in one sentence.\n",
    "    2. Highlight the key result by enclosing it in double asterisks (**).\n",
    "    3. Avoid using markdown or unnecessary formatting.\n",
    "\n",
    "    '''),\n",
    "        (\"human\", \"User question: {question}\\n\\nQuery results: {results}\\n\\nConclusion:\")\n",
    "    ])\n",
    "    chain = prompt | llm | output_parser\n",
    "    response = chain.invoke({\"question\":question, \"results\":results})\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= format_results ========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'The product category generating the most revenue is **beleza_saude**. \\n'}"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_results({\n",
    "    \"question\":question, \n",
    "    \"query_result\":query_result\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format response for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_visualization(state: dict) -> dict:\n",
    "    print(\"========= choose_visualization ========\")\n",
    "    \"\"\"Choose an appropriate visualization for the data.\"\"\"\n",
    "    question = state['question']\n",
    "    results = state['query_result']\n",
    "    sql_query = state['sql_query']\n",
    "\n",
    "    if results == \"NOT_RELEVANT\":\n",
    "        return {\"visualization\": \"none\", \"visualization_reasoning\": \"No visualization needed for irrelevant questions.\"}\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant recommending the best data visualizations. Based on the user's question, SQL query, and query results, suggest the most suitable graph or chart type.\n",
    "\n",
    "    ### Chart Types:\n",
    "    - **Bar Graph**: For comparing categorical data or showing changes over time with more than two categories.\n",
    "    - **Horizontal Bar Graph**: For comparing few categories or when there's a large disparity between them.\n",
    "    - **Scatter Plot**: For showing relationships or distributions between two continuous numerical variables.\n",
    "    - **Pie Chart**: For displaying proportions or percentages of a whole.\n",
    "    - **Line Graph**: For showing trends over time, where both x and y axes are continuous.\n",
    "    - **None**: If no visualization is appropriate.\n",
    "\n",
    "    ### Consider These Questions:\n",
    "    1. **Aggregations**: Summarize data (e.g., average revenue by month)  Line Graph.\n",
    "    2. **Comparisons**: Compare metrics (e.g., sales of Product A vs. Product B)  Line or Bar Graph.\n",
    "    3. **Distributions**: Show data distribution (e.g., age distribution)  Scatter Plot.\n",
    "    4. **Trends Over Time**: Show changes over time (e.g., website visits)  Line Graph.\n",
    "    5. **Proportions**: Show percentages (e.g., market share)  Pie Chart.\n",
    "    6. **Correlations**: Show relationships (e.g., marketing spend vs. revenue)  Scatter Plot.\n",
    "\n",
    "    ### Format:\n",
    "         {{\n",
    "            recommended_visualization: string (bar | horizontal_bar | line | pie | scatter | none),\n",
    "            reason: Brief explanation of your recommendation\n",
    "         }}\n",
    "    '''),\n",
    "        (\"human\", '''\n",
    "    User question: {question}\n",
    "    SQL query: {sql_query}\n",
    "    Query results: {results}\n",
    "\n",
    "    Recommend a visualization:\n",
    "        '''),\n",
    "    ])\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    response = chain.invoke({\"question\":question,\"sql_query\":sql_query,\"results\":results})\n",
    "\n",
    "    return {\n",
    "        \"recommended_visualization\":response[\"recommended_visualization\"],\n",
    "        \"reason\":response[\"reason\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= choose_visualization ========\n"
     ]
    }
   ],
   "source": [
    "visualization = choose_visualization({\n",
    "    \"question\":question, \n",
    "    \"query_result\":query_result,\n",
    "    \"sql_query\":valid_sql_query\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommended_visualization': 'bar',\n",
       " 'reason': 'The query compares revenue generated by different product categories. A bar graph effectively visualizes categorical data and allows for easy comparison of revenue values.'}"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseFormatter(ABC):\n",
    "    def __init__(self, llm_manager):\n",
    "        self.llm = llm_manager\n",
    "\n",
    "    @abstractmethod\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        \"\"\"Formats data for visualization.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_axis_label(self, question, data, axis):\n",
    "        \"\"\"Get axis label using the LLM.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"You are a data labeling expert. Given a question and some data, provide a concise and relevant label for the {{axis}}-axis.\"),\n",
    "            (\"human\", f\"Question: {question}\\nData : {data}\\n\\nProvide a concise label for the {axis}-axis.\"),\n",
    "        ])\n",
    "        chain = prompt | llm | output_parser\n",
    "        return chain.invoke({\"question\":question, \"data\":query_result, \"axis\":\"y\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Revenue  \\n', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 1371, 'total_tokens': 1376, 'completion_time': 0.009090909, 'prompt_time': 0.044620864, 'queue_time': 0.002871516999999997, 'total_time': 0.053711773}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6720a7e6-fc9f-4c7c-86ac-e4a8f271e7a3-0', usage_metadata={'input_tokens': 1371, 'output_tokens': 5, 'total_tokens': 1376})"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"You are a data labeling expert. Given a question and some data, provide a concise and relevant label for the {{axis}}-axis.\"),\n",
    "    (\"human\", f\"Question: {question}\\nData : {{data}}\\n\\nProvide a concise label for the {{axis}}-axis.\"),\n",
    "])\n",
    "chain = prompt2 | llm \n",
    "chain.invoke({\"question\":question, \"data\":query_result, \"axis\":\"y\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chart formaters\n",
    "\n",
    "class LineChartFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        print(\"=========Line chart trigger==========\")\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        x_values = [str(row[0]) for row in results]\n",
    "        y_values = [float(row[1]) for row in results]\n",
    "\n",
    "        y_axis_label = self.get_axis_label(question, results[:2], \"y\")\n",
    "        \n",
    "        return {\n",
    "            \"xValues\": x_values,\n",
    "            \"yValues\": [{\"data\": y_values, \"label\": y_axis_label.strip()}],\n",
    "        }\n",
    "\n",
    "\n",
    "class ScatterPlotFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        print(\"=========Scatter plot trigger==========\")\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        series = [{\"x\": float(x), \"y\": float(y), \"id\": i + 1} for i, (x, y) in enumerate(results)]\n",
    "        return {\"series\": [{\"data\": series, \"label\": \"Data Points\"}]}\n",
    "\n",
    "\n",
    "class BarChartFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        print(\"=========Bar chart trigger==========\")\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        labels = [str(row[0]) for row in results]\n",
    "        data = [float(row[1]) for row in results]\n",
    "        # print(\"=============Trigger==========\")\n",
    "        y_axis_label = self.get_axis_label(question, results[:2], \"y\")\n",
    "\n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"values\": [{\"data\": data, \"label\": y_axis_label.strip()}]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatterRegistry:\n",
    "    def __init__(self, llm_manager):\n",
    "        self.formatters = {\n",
    "            \"line\": LineChartFormatter(llm_manager),\n",
    "            \"scatter\": ScatterPlotFormatter(llm_manager),\n",
    "            \"bar\": BarChartFormatter(llm_manager),\n",
    "            # Add other visualizers like \"horizontal_bar\", \"pie\", etc.\n",
    "        }\n",
    "\n",
    "    def get_formatter(self, visualization):\n",
    "        print(\"Selector method triggered\")\n",
    "        return self.formatters.get(visualization, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFormatter:\n",
    "    def __init__(self):\n",
    "        self.llm_manager = llm\n",
    "        self.registry = FormatterRegistry(self.llm_manager)\n",
    "\n",
    "    def format_data_for_visualization(self, state: dict) -> dict:\n",
    "        print(\"========= Main method to format data for visualization. ========\")\n",
    "        \"\"\"Main method to format data for visualization.\"\"\"\n",
    "        print(state)\n",
    "        visualization = state['recommended_visualization']\n",
    "        results = state['query_result']\n",
    "        question = state['question']\n",
    "\n",
    "        formatter = self.registry.get_formatter(visualization)\n",
    "\n",
    "        if formatter is not None:\n",
    "            try:\n",
    "                return {\"formatted_data_for_visualization\": formatter.format(results, question)}\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "        \n",
    "        return {\"formatted_data_for_visualization\": None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n"
     ]
    }
   ],
   "source": [
    "print(visualization[\"recommended_visualization\"])\n",
    "visualization_data = DataFormatter().format_data_for_visualization({\n",
    "    \"recommended_visualization\": visualization[\"recommended_visualization\"], \n",
    "    \"query_result\": query_result, \n",
    "    \"question\": question\n",
    "    })\n",
    "# visualization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formatted_data_for_visualization': {'labels': ['beleza_saude', 'relogios_presentes', 'cama_mesa_banho', 'esporte_lazer', 'informatica_acessorios', 'moveis_decoracao', 'cool_stuff', 'utilidades_domesticas', 'automotivo', 'ferramentas_jardim', 'brinquedos', 'bebes', 'perfumaria', 'telefonia', 'moveis_escritorio', 'papelaria', 'pcs', 'pet_shop', 'instrumentos_musicais', 'eletroportateis', 'eletronicos', 'consoles_games', 'fashion_bolsas_e_acessorios', 'construcao_ferramentas_construcao', 'malas_acessorios', 'eletrodomesticos_2', 'casa_construcao', 'eletrodomesticos', 'agro_industria_e_comercio', 'moveis_sala', 'telefonia_fixa', 'casa_conforto', 'climatizacao', 'audio', 'portateis_casa_forno_e_cafe', 'livros_interesse_geral', 'moveis_cozinha_area_de_servico_jantar_e_jardim', 'construcao_ferramentas_iluminacao', 'construcao_ferramentas_seguranca', 'industria_comercio_e_negocios', 'alimentos', 'market_place', 'construcao_ferramentas_jardim', 'artes', 'fashion_calcados', 'bebidas', 'sinalizacao_e_seguranca', 'moveis_quarto', 'livros_tecnicos', 'construcao_ferramentas_ferramentas', 'alimentos_bebidas', 'fashion_roupa_masculina', 'fashion_underwear_e_moda_praia', 'artigos_de_natal', 'tablets_impressao_imagem', 'cine_foto', 'musica', 'dvds_blu_ray', 'livros_importados', 'artigos_de_festas', 'moveis_colchao_e_estofado', 'portateis_cozinha_e_preparadores_de_alimentos', 'fashion_roupa_feminina', 'fashion_esporte', 'la_cuisine', 'artes_e_artesanato', 'fraldas_higiene', 'pc_gamer', 'flores', 'casa_conforto_2', 'cds_dvds_musicais', 'fashion_roupa_infanto_juvenil', 'seguros_e_servicos'], 'values': [{'data': [1258681.34, 1205005.68, 1036988.68, 988048.97, 911954.32, 729762.49, 635290.85, 632248.66, 592720.11, 485256.46, 483946.6, 411764.89, 399124.87, 323667.52999999997, 273960.7, 230943.23, 222963.13, 214315.41, 191498.88, 190648.58, 160246.74, 157465.22, 152823.54, 144677.59, 140429.98, 113317.74, 83088.12, 80171.53, 72530.47, 68916.56, 59583.0, 58572.04, 55024.96, 50688.5, 47445.71, 46856.88, 46328.37, 41080.0, 40544.52, 39669.61, 29393.41, 28378.47, 25715.89, 24202.64, 23562.77, 22428.7, 21509.23, 20028.78, 19096.06, 15903.95, 15179.48, 10797.82, 9541.55, 8800.82, 7528.41, 6933.46, 6034.35, 5999.39, 4639.85, 4485.18, 4368.08, 3968.5299999999997, 2803.64, 2119.51, 2054.99, 1814.01, 1567.59, 1545.95, 1110.04, 760.27, 730.0, 569.85, 283.28999999999996], 'label': 'Revenue'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(visualization_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Annotated, Dict\n",
    "from typing_extensions import TypedDict\n",
    "import operator\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "    schema: List[Dict]\n",
    "    parsed_question: dict\n",
    "    sql_query: str\n",
    "    sql_valid: bool\n",
    "    sql_issues: str\n",
    "    query_result: List[Any]\n",
    "    recommended_visualization:str\n",
    "    reason:str\n",
    "    visualization: Annotated[str, operator.add]\n",
    "    # visualization_reason: Annotated[str, operator.add]\n",
    "    # formatted_data_for_visualization: Dict[str, Any]\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    parsed_question: Dict[str, Any]\n",
    "    unique_nouns: List[str]\n",
    "    sql_query: str\n",
    "    sql_valid: bool\n",
    "    sql_issues: str\n",
    "    query_result: List[Any]\n",
    "    recommended_visualization:str\n",
    "    reason:str\n",
    "    results: List[Any]\n",
    "    answer: Annotated[str, operator.add]\n",
    "    error: str\n",
    "    visualization: Annotated[str, operator.add]\n",
    "    visualization_reason: Annotated[str, operator.add]\n",
    "    formatted_data_for_visualization: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "class WorkflowManager:\n",
    "    def __init__(self):\n",
    "        self.data_formatter = DataFormatter()\n",
    "\n",
    "    def create_workflow(self) -> StateGraph:\n",
    "        \"\"\"Create and configure the workflow graph.\"\"\"\n",
    "        workflow = StateGraph(input=InputState, output=OutputState)\n",
    "\n",
    "        # Add nodes to the graph\n",
    "        workflow.add_node(\"parse_question\", get_parse_question)\n",
    "        workflow.add_node(\"get_unique_nouns\", get_unique_nouns)\n",
    "        workflow.add_node(\"generate_sql\", generete_sql_query)\n",
    "        workflow.add_node(\"validate_and_fix_sql\", validate_and_fix_sql)\n",
    "        workflow.add_node(\"execute_sql\", execute_query)\n",
    "        workflow.add_node(\"format_results\", format_results)\n",
    "        workflow.add_node(\"choose_visualization\", choose_visualization)\n",
    "        workflow.add_node(\"format_data_for_visualization\", self.data_formatter.format_data_for_visualization)\n",
    "        \n",
    "        # Define edges\n",
    "        workflow.add_edge(START, \"parse_question\")\n",
    "        workflow.add_edge(\"parse_question\", \"get_unique_nouns\")\n",
    "        workflow.add_edge(\"get_unique_nouns\", \"generate_sql\")\n",
    "        workflow.add_edge(\"generate_sql\", \"validate_and_fix_sql\")\n",
    "        workflow.add_edge(\"validate_and_fix_sql\", \"execute_sql\")\n",
    "        workflow.add_edge(\"execute_sql\", \"format_results\")\n",
    "        workflow.add_edge(\"execute_sql\", \"choose_visualization\")\n",
    "        workflow.add_edge(\"choose_visualization\", \"format_data_for_visualization\")\n",
    "        workflow.add_edge(\"format_data_for_visualization\", END)\n",
    "        workflow.add_edge(\"format_results\", END)\n",
    "        # workflow.set_entry_point(\"parse_question\")\n",
    "\n",
    "        return workflow\n",
    "    \n",
    "    def returnGraph(self):\n",
    "        return self.create_workflow().compile()\n",
    "\n",
    "    def run_sql_agent(self, question: str, schema: List[Dict]) -> dict:\n",
    "        \"\"\"Run the SQL agent workflow and return the formatted answer and visualization recommendation.\"\"\"\n",
    "        app = self.create_workflow().compile()\n",
    "        for event in app.stream({\"question\": question, \"schema\": schema}):\n",
    "            for value in event.values():\n",
    "                print(value)\n",
    "\n",
    "        # result = app.invoke({\"question\": question, \"schema\": schema})\n",
    "        # print(result)\n",
    "        # return {\n",
    "        #     \"answer\": result['answer'],\n",
    "        #     \"visualization\": result['visualization'],\n",
    "        #     \"visualization_reason\": result['visualization_reason'],\n",
    "        #     \"formatted_data_for_visualization\": result['formatted_data_for_visualization']\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/21nt5n9d46bgh23zzhvzdgk00000gn/T/ipykernel_66944/2722828617.py:11: LangGraphDeprecationWarning: Initializing StateGraph without state_schema is deprecated. Please pass in an explicit state_schema instead of just an input and output schema.\n",
      "  workflow = StateGraph(input=InputState, output=OutputState)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which product categories generate the most revenue?', 'schema': [{'table_name': 'olist_products_dataset', 'schema': [{'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'product_category_name', 'type': 'TEXT', 'nullable': True}, {'name': 'product_name_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_description_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_photos_qty', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_weight_g', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_length_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_height_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_width_cm', 'type': 'FLOAT', 'nullable': True}]}, {'table_name': 'olist_orders_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_status', 'type': 'TEXT', 'nullable': True}, {'name': 'order_purchase_timestamp', 'type': 'TEXT', 'nullable': True}, {'name': 'order_approved_at', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_carrier_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_customer_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_estimated_delivery_date', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_customers_dataset', 'schema': [{'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_unique_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_zip_code_prefix', 'type': 'BIGINT', 'nullable': True}, {'name': 'customer_city', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_state', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_order_items_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_item_id', 'type': 'BIGINT', 'nullable': True}, {'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'seller_id', 'type': 'TEXT', 'nullable': True}, {'name': 'shipping_limit_date', 'type': 'TEXT', 'nullable': True}, {'name': 'price', 'type': 'FLOAT', 'nullable': True}, {'name': 'freight_value', 'type': 'FLOAT', 'nullable': True}]}], 'visualization': ''}\n",
      "======= get_parse_question =======\n",
      "{'parsed_question': {'is_relevant': True, 'relevant_tables': [{'table_name': 'olist_order_items_dataset', 'columns': ['order_id', 'product_id', 'price', 'freight_value'], 'noun_columns': []}, {'table_name': 'olist_products_dataset', 'columns': ['product_id', 'product_category_name'], 'noun_columns': ['product_category_name']}]}}\n",
      "======= Find unique nouns in relevant tables and columns. =======\n",
      "{'unique_nouns': {'olist_order_items_dataset': {}, 'olist_products_dataset': {'product_category_name': {'fraldas_higiene', 'fashion_roupa_masculina', 'consoles_games', 'moveis_quarto', 'informatica_acessorios', 'industria_comercio_e_negocios', 'eletrodomesticos', 'construcao_ferramentas_ferramentas', 'beleza_saude', 'bebes', 'moveis_escritorio', 'seguros_e_servicos', 'livros_interesse_geral', 'construcao_ferramentas_iluminacao', 'flores', 'malas_acessorios', 'fashion_esporte', 'telefonia', 'moveis_colchao_e_estofado', 'fashion_calcados', 'artes', 'pet_shop', 'pcs', 'fashion_underwear_e_moda_praia', 'brinquedos', 'la_cuisine', 'audio', 'portateis_casa_forno_e_cafe', 'pc_gamer', 'perfumaria', 'telefonia_fixa', 'construcao_ferramentas_jardim', 'cine_foto', 'casa_conforto_2', 'esporte_lazer', 'alimentos_bebidas', 'bebidas', 'livros_tecnicos', 'portateis_cozinha_e_preparadores_de_alimentos', 'musica', 'fashion_roupa_infanto_juvenil', 'fashion_bolsas_e_acessorios', 'alimentos', 'utilidades_domesticas', 'agro_industria_e_comercio', 'dvds_blu_ray', 'cds_dvds_musicais', 'construcao_ferramentas_construcao', 'casa_conforto', 'livros_importados', 'cama_mesa_banho', 'moveis_decoracao', 'cool_stuff', 'climatizacao', 'market_place', 'eletroportateis', 'relogios_presentes', 'artigos_de_festas', 'tablets_impressao_imagem', 'instrumentos_musicais', 'eletronicos', 'eletrodomesticos_2', 'artes_e_artesanato', 'moveis_cozinha_area_de_servico_jantar_e_jardim', 'casa_construcao', 'construcao_ferramentas_seguranca', 'papelaria', 'ferramentas_jardim', 'moveis_sala', 'sinalizacao_e_seguranca', 'automotivo', 'fashion_roupa_feminina', 'artigos_de_natal'}}}}\n",
      "======= generete_sql_query =======\n",
      "{'sql_query': 'SELECT `product_category_name`, SUM(`price`) AS `total_revenue`\\nFROM `olist_products_dataset`\\nJOIN `olist_order_items_dataset` ON `olist_products_dataset`.`product_id` = `olist_order_items_dataset`.`product_id`\\nWHERE `product_category_name` IS NOT NULL AND `price` IS NOT NULL \\nAND `product_category_name` != \"\" AND `price` != \"\" \\nAND `product_category_name` != \"N/A\" AND `price` != \"N/A\"\\nGROUP BY `product_category_name`\\nORDER BY `total_revenue` DESC'}\n",
      "========= validate_and_fix_sql ========\n",
      "{'sql_query': 'SELECT `product_category_name`, SUM(`price`) AS `total_revenue`\\nFROM `olist_products_dataset`\\nJOIN `olist_order_items_dataset` ON `olist_products_dataset`.`product_id` = `olist_order_items_dataset`.`product_id`\\nWHERE `product_category_name` IS NOT NULL AND `price` IS NOT NULL \\nAND `product_category_name` != \"\" AND `price` != \"\" \\nAND `product_category_name` != \"N/A\" AND `price` != \"N/A\"\\nGROUP BY `product_category_name`\\nORDER BY `total_revenue` DESC', 'sql_valid': True}\n",
      "======= execute_query =======\n",
      "{'query_result': [('beleza_saude', 1258681.34), ('relogios_presentes', 1205005.68), ('cama_mesa_banho', 1036988.68), ('esporte_lazer', 988048.97), ('informatica_acessorios', 911954.32), ('moveis_decoracao', 729762.49), ('cool_stuff', 635290.85), ('utilidades_domesticas', 632248.66), ('automotivo', 592720.11), ('ferramentas_jardim', 485256.46), ('brinquedos', 483946.6), ('bebes', 411764.89), ('perfumaria', 399124.87), ('telefonia', 323667.52999999997), ('moveis_escritorio', 273960.7), ('papelaria', 230943.23), ('pcs', 222963.13), ('pet_shop', 214315.41), ('instrumentos_musicais', 191498.88), ('eletroportateis', 190648.58), ('eletronicos', 160246.74), ('consoles_games', 157465.22), ('fashion_bolsas_e_acessorios', 152823.54), ('construcao_ferramentas_construcao', 144677.59), ('malas_acessorios', 140429.98), ('eletrodomesticos_2', 113317.74), ('casa_construcao', 83088.12), ('eletrodomesticos', 80171.53), ('agro_industria_e_comercio', 72530.47), ('moveis_sala', 68916.56), ('telefonia_fixa', 59583.0), ('casa_conforto', 58572.04), ('climatizacao', 55024.96), ('audio', 50688.5), ('portateis_casa_forno_e_cafe', 47445.71), ('livros_interesse_geral', 46856.88), ('moveis_cozinha_area_de_servico_jantar_e_jardim', 46328.37), ('construcao_ferramentas_iluminacao', 41080.0), ('construcao_ferramentas_seguranca', 40544.52), ('industria_comercio_e_negocios', 39669.61), ('alimentos', 29393.41), ('market_place', 28378.47), ('construcao_ferramentas_jardim', 25715.89), ('artes', 24202.64), ('fashion_calcados', 23562.77), ('bebidas', 22428.7), ('sinalizacao_e_seguranca', 21509.23), ('moveis_quarto', 20028.78), ('livros_tecnicos', 19096.06), ('construcao_ferramentas_ferramentas', 15903.95), ('alimentos_bebidas', 15179.48), ('fashion_roupa_masculina', 10797.82), ('fashion_underwear_e_moda_praia', 9541.55), ('artigos_de_natal', 8800.82), ('tablets_impressao_imagem', 7528.41), ('cine_foto', 6933.46), ('musica', 6034.35), ('dvds_blu_ray', 5999.39), ('livros_importados', 4639.85), ('artigos_de_festas', 4485.18), ('moveis_colchao_e_estofado', 4368.08), ('portateis_cozinha_e_preparadores_de_alimentos', 3968.5299999999997), ('fashion_roupa_feminina', 2803.64), ('fashion_esporte', 2119.51), ('la_cuisine', 2054.99), ('artes_e_artesanato', 1814.01), ('fraldas_higiene', 1567.59), ('pc_gamer', 1545.95), ('flores', 1110.04), ('casa_conforto_2', 760.27), ('cds_dvds_musicais', 730.0), ('fashion_roupa_infanto_juvenil', 569.85), ('seguros_e_servicos', 283.28999999999996)]}\n",
      "========= format_results ========\n",
      "========= choose_visualization ========\n",
      "{'answer': 'The product category that generates the most revenue is **beleza_saude**. \\n'}\n",
      "{'recommended_visualization': 'bar', 'reason': 'The query results show product categories and their total revenue, making a bar graph suitable for comparing the revenue generated by each category.'}\n",
      "========= Main method to format data for visualization. ========\n",
      "{'question': 'Which product categories generate the most revenue?', 'schema': [{'table_name': 'olist_products_dataset', 'schema': [{'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'product_category_name', 'type': 'TEXT', 'nullable': True}, {'name': 'product_name_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_description_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_photos_qty', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_weight_g', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_length_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_height_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_width_cm', 'type': 'FLOAT', 'nullable': True}]}, {'table_name': 'olist_orders_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_status', 'type': 'TEXT', 'nullable': True}, {'name': 'order_purchase_timestamp', 'type': 'TEXT', 'nullable': True}, {'name': 'order_approved_at', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_carrier_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_customer_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_estimated_delivery_date', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_customers_dataset', 'schema': [{'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_unique_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_zip_code_prefix', 'type': 'BIGINT', 'nullable': True}, {'name': 'customer_city', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_state', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_order_items_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_item_id', 'type': 'BIGINT', 'nullable': True}, {'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'seller_id', 'type': 'TEXT', 'nullable': True}, {'name': 'shipping_limit_date', 'type': 'TEXT', 'nullable': True}, {'name': 'price', 'type': 'FLOAT', 'nullable': True}, {'name': 'freight_value', 'type': 'FLOAT', 'nullable': True}]}], 'parsed_question': {'is_relevant': True, 'relevant_tables': [{'table_name': 'olist_order_items_dataset', 'columns': ['order_id', 'product_id', 'price', 'freight_value'], 'noun_columns': []}, {'table_name': 'olist_products_dataset', 'columns': ['product_id', 'product_category_name'], 'noun_columns': ['product_category_name']}]}, 'sql_query': 'SELECT `product_category_name`, SUM(`price`) AS `total_revenue`\\nFROM `olist_products_dataset`\\nJOIN `olist_order_items_dataset` ON `olist_products_dataset`.`product_id` = `olist_order_items_dataset`.`product_id`\\nWHERE `product_category_name` IS NOT NULL AND `price` IS NOT NULL \\nAND `product_category_name` != \"\" AND `price` != \"\" \\nAND `product_category_name` != \"N/A\" AND `price` != \"N/A\"\\nGROUP BY `product_category_name`\\nORDER BY `total_revenue` DESC', 'sql_valid': True, 'query_result': [('beleza_saude', 1258681.34), ('relogios_presentes', 1205005.68), ('cama_mesa_banho', 1036988.68), ('esporte_lazer', 988048.97), ('informatica_acessorios', 911954.32), ('moveis_decoracao', 729762.49), ('cool_stuff', 635290.85), ('utilidades_domesticas', 632248.66), ('automotivo', 592720.11), ('ferramentas_jardim', 485256.46), ('brinquedos', 483946.6), ('bebes', 411764.89), ('perfumaria', 399124.87), ('telefonia', 323667.52999999997), ('moveis_escritorio', 273960.7), ('papelaria', 230943.23), ('pcs', 222963.13), ('pet_shop', 214315.41), ('instrumentos_musicais', 191498.88), ('eletroportateis', 190648.58), ('eletronicos', 160246.74), ('consoles_games', 157465.22), ('fashion_bolsas_e_acessorios', 152823.54), ('construcao_ferramentas_construcao', 144677.59), ('malas_acessorios', 140429.98), ('eletrodomesticos_2', 113317.74), ('casa_construcao', 83088.12), ('eletrodomesticos', 80171.53), ('agro_industria_e_comercio', 72530.47), ('moveis_sala', 68916.56), ('telefonia_fixa', 59583.0), ('casa_conforto', 58572.04), ('climatizacao', 55024.96), ('audio', 50688.5), ('portateis_casa_forno_e_cafe', 47445.71), ('livros_interesse_geral', 46856.88), ('moveis_cozinha_area_de_servico_jantar_e_jardim', 46328.37), ('construcao_ferramentas_iluminacao', 41080.0), ('construcao_ferramentas_seguranca', 40544.52), ('industria_comercio_e_negocios', 39669.61), ('alimentos', 29393.41), ('market_place', 28378.47), ('construcao_ferramentas_jardim', 25715.89), ('artes', 24202.64), ('fashion_calcados', 23562.77), ('bebidas', 22428.7), ('sinalizacao_e_seguranca', 21509.23), ('moveis_quarto', 20028.78), ('livros_tecnicos', 19096.06), ('construcao_ferramentas_ferramentas', 15903.95), ('alimentos_bebidas', 15179.48), ('fashion_roupa_masculina', 10797.82), ('fashion_underwear_e_moda_praia', 9541.55), ('artigos_de_natal', 8800.82), ('tablets_impressao_imagem', 7528.41), ('cine_foto', 6933.46), ('musica', 6034.35), ('dvds_blu_ray', 5999.39), ('livros_importados', 4639.85), ('artigos_de_festas', 4485.18), ('moveis_colchao_e_estofado', 4368.08), ('portateis_cozinha_e_preparadores_de_alimentos', 3968.5299999999997), ('fashion_roupa_feminina', 2803.64), ('fashion_esporte', 2119.51), ('la_cuisine', 2054.99), ('artes_e_artesanato', 1814.01), ('fraldas_higiene', 1567.59), ('pc_gamer', 1545.95), ('flores', 1110.04), ('casa_conforto_2', 760.27), ('cds_dvds_musicais', 730.0), ('fashion_roupa_infanto_juvenil', 569.85), ('seguros_e_servicos', 283.28999999999996)], 'recommended_visualization': 'bar', 'reason': 'The query results show product categories and their total revenue, making a bar graph suitable for comparing the revenue generated by each category.', 'visualization': ''}\n",
      "Selector method triggered\n",
      "=========Bar chart trigger==========\n",
      "{'formatted_data_for_visualization': {'labels': ['beleza_saude', 'relogios_presentes', 'cama_mesa_banho', 'esporte_lazer', 'informatica_acessorios', 'moveis_decoracao', 'cool_stuff', 'utilidades_domesticas', 'automotivo', 'ferramentas_jardim', 'brinquedos', 'bebes', 'perfumaria', 'telefonia', 'moveis_escritorio', 'papelaria', 'pcs', 'pet_shop', 'instrumentos_musicais', 'eletroportateis', 'eletronicos', 'consoles_games', 'fashion_bolsas_e_acessorios', 'construcao_ferramentas_construcao', 'malas_acessorios', 'eletrodomesticos_2', 'casa_construcao', 'eletrodomesticos', 'agro_industria_e_comercio', 'moveis_sala', 'telefonia_fixa', 'casa_conforto', 'climatizacao', 'audio', 'portateis_casa_forno_e_cafe', 'livros_interesse_geral', 'moveis_cozinha_area_de_servico_jantar_e_jardim', 'construcao_ferramentas_iluminacao', 'construcao_ferramentas_seguranca', 'industria_comercio_e_negocios', 'alimentos', 'market_place', 'construcao_ferramentas_jardim', 'artes', 'fashion_calcados', 'bebidas', 'sinalizacao_e_seguranca', 'moveis_quarto', 'livros_tecnicos', 'construcao_ferramentas_ferramentas', 'alimentos_bebidas', 'fashion_roupa_masculina', 'fashion_underwear_e_moda_praia', 'artigos_de_natal', 'tablets_impressao_imagem', 'cine_foto', 'musica', 'dvds_blu_ray', 'livros_importados', 'artigos_de_festas', 'moveis_colchao_e_estofado', 'portateis_cozinha_e_preparadores_de_alimentos', 'fashion_roupa_feminina', 'fashion_esporte', 'la_cuisine', 'artes_e_artesanato', 'fraldas_higiene', 'pc_gamer', 'flores', 'casa_conforto_2', 'cds_dvds_musicais', 'fashion_roupa_infanto_juvenil', 'seguros_e_servicos'], 'values': [{'data': [1258681.34, 1205005.68, 1036988.68, 988048.97, 911954.32, 729762.49, 635290.85, 632248.66, 592720.11, 485256.46, 483946.6, 411764.89, 399124.87, 323667.52999999997, 273960.7, 230943.23, 222963.13, 214315.41, 191498.88, 190648.58, 160246.74, 157465.22, 152823.54, 144677.59, 140429.98, 113317.74, 83088.12, 80171.53, 72530.47, 68916.56, 59583.0, 58572.04, 55024.96, 50688.5, 47445.71, 46856.88, 46328.37, 41080.0, 40544.52, 39669.61, 29393.41, 28378.47, 25715.89, 24202.64, 23562.77, 22428.7, 21509.23, 20028.78, 19096.06, 15903.95, 15179.48, 10797.82, 9541.55, 8800.82, 7528.41, 6933.46, 6034.35, 5999.39, 4639.85, 4485.18, 4368.08, 3968.5299999999997, 2803.64, 2119.51, 2054.99, 1814.01, 1567.59, 1545.95, 1110.04, 760.27, 730.0, 569.85, 283.28999999999996], 'label': 'Revenue (USD)'}]}}\n"
     ]
    }
   ],
   "source": [
    "workflow = WorkflowManager()\n",
    "workflow.run_sql_agent(\n",
    "    schema=schema,question=\"Which product categories generate the most revenue?\"\n",
    ")\n",
    "# app = workflow.returnGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/21nt5n9d46bgh23zzhvzdgk00000gn/T/ipykernel_66944/1950226658.py:11: LangGraphDeprecationWarning: Initializing StateGraph without state_schema is deprecated. Please pass in an explicit state_schema instead of just an input and output schema.\n",
      "  workflow = StateGraph(input=InputState, output=OutputState)\n"
     ]
    }
   ],
   "source": [
    "app = workflow.returnGraph()\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/21nt5n9d46bgh23zzhvzdgk00000gn/T/ipykernel_66944/70840226.py:11: LangGraphDeprecationWarning: Initializing StateGraph without state_schema is deprecated. Please pass in an explicit state_schema instead of just an input and output schema.\n",
      "  workflow = StateGraph(input=InputState, output=OutputState)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[574], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sql_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhich product categories generate the most revenue?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[569], line 44\u001b[0m, in \u001b[0;36mWorkflowManager.run_sql_agent\u001b[0;34m(self, question, schema)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the SQL agent workflow and return the formatted answer and visualization recommendation.\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_workflow()\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: schema}):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(value)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1298\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1293\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1294\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1295\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1296\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1297\u001b[0m     ):\n\u001b[0;32m-> 1298\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1299\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1300\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1301\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1302\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1303\u001b[0m         ):\n\u001b[1;32m   1304\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:409\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:183\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 183\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[573], line 7\u001b[0m, in \u001b[0;36mget_parse_question\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_parse_question\u001b[39m(state: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m      6\u001b[0m     question \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m======= get_parse_question =======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(state)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'schema'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
