{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat With Multiple CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take csv or excel sheet & upload data in sqlite3\n",
    "# Take User questions\n",
    "# Parse questions & get relevant tables and columns (LLM)\n",
    "# Get Unique noun\n",
    "# Generate SQL query (LLM)\n",
    "# Validate SQL Query if something wrong fix it (LLM)\n",
    "# Execute SQL\n",
    "#     If there is no error & SQL Query is relevent\n",
    "#         Choose visualization (LLM)\n",
    "#         format data for visualization (LLM)\n",
    "#     Else\n",
    "#         Format result (LLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# llm = Ollama(model=\"llama3.1:latest\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(groq_api_key=\"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\", model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert data in sequalite\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Function to read CSV/Excel and insert into SQLite database\n",
    "def insert_data_to_sqlite(file_path):\n",
    "    # Extract the file name without extension to use as table name\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Read the data (change this to pd.read_excel() for Excel files)\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Create a SQLite database (or connect if it already exists)\n",
    "    engine = create_engine('sqlite:///lumin.db')\n",
    "    \n",
    "    # Insert data into the SQLite database with the table name as the file name\n",
    "    data.to_sql(file_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Data from {file_path} has been inserted into the '{file_name}' table in the 'lumin.db' database.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/spandanjoshi/Desktop/LLM/lumin/backend/notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your CSV/Excel file\n",
    "ecom_data = [\n",
    "  \"olist_customers_dataset.csv\",\n",
    "  \"olist_geolocation_dataset.csv\",\n",
    "  \"olist_order_items_dataset.csv\",\n",
    "  \"olist_order_payments_dataset.csv\",\n",
    "  \"olist_order_reviews_dataset.csv\",\n",
    "  \"olist_orders_dataset.csv\",\n",
    "  \"olist_products_dataset.csv\",\n",
    "  \"olist_sellers_dataset.csv\",\n",
    "  \"product_category_name_translation.csv\"\n",
    "]\n",
    "\n",
    "# for data in ecom_data:\n",
    "#     path = (f\"ecommerce/{data}\")\n",
    "#     # \n",
    "    \n",
    "#     file_data = os.path.abspath(path)\n",
    "#     insert_data_to_sqlite(file_data)\n",
    "#     print(file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'table_name': 'olist_products_dataset', 'schema': [{'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'product_category_name', 'type': 'TEXT', 'nullable': True}, {'name': 'product_name_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_description_lenght', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_photos_qty', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_weight_g', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_length_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_height_cm', 'type': 'FLOAT', 'nullable': True}, {'name': 'product_width_cm', 'type': 'FLOAT', 'nullable': True}]}, {'table_name': 'olist_orders_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_status', 'type': 'TEXT', 'nullable': True}, {'name': 'order_purchase_timestamp', 'type': 'TEXT', 'nullable': True}, {'name': 'order_approved_at', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_carrier_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_delivered_customer_date', 'type': 'TEXT', 'nullable': True}, {'name': 'order_estimated_delivery_date', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_customers_dataset', 'schema': [{'name': 'customer_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_unique_id', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_zip_code_prefix', 'type': 'BIGINT', 'nullable': True}, {'name': 'customer_city', 'type': 'TEXT', 'nullable': True}, {'name': 'customer_state', 'type': 'TEXT', 'nullable': True}]}, {'table_name': 'olist_order_items_dataset', 'schema': [{'name': 'order_id', 'type': 'TEXT', 'nullable': True}, {'name': 'order_item_id', 'type': 'BIGINT', 'nullable': True}, {'name': 'product_id', 'type': 'TEXT', 'nullable': True}, {'name': 'seller_id', 'type': 'TEXT', 'nullable': True}, {'name': 'shipping_limit_date', 'type': 'TEXT', 'nullable': True}, {'name': 'price', 'type': 'FLOAT', 'nullable': True}, {'name': 'freight_value', 'type': 'FLOAT', 'nullable': True}]}]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from typing import List, Dict\n",
    "\n",
    "# Assuming you have an SQLAlchemy engine created\n",
    "engine = create_engine('sqlite:///lumin.db')  \n",
    "\n",
    "def get_schemas(table_names: List[str]) -> List[Dict]:\n",
    "    try:\n",
    "        # Create an inspector object\n",
    "        inspector = inspect(engine)\n",
    "\n",
    "        # Initialize an array to hold the schema information for all tables\n",
    "        schemas_info = []\n",
    "\n",
    "        for table_name in table_names:\n",
    "            schema_info = {\n",
    "                \"table_name\": table_name,\n",
    "                \"schema\": []\n",
    "            }\n",
    "\n",
    "            # Get the columns for the specified table\n",
    "            columns = inspector.get_columns(table_name)\n",
    "\n",
    "            # Collect column information\n",
    "            for column in columns:\n",
    "                schema_info[\"schema\"].append({\n",
    "                    \"name\": column['name'],\n",
    "                    \"type\": str(column['type']),\n",
    "                    \"nullable\": column['nullable']\n",
    "                })\n",
    "\n",
    "            # Append the schema information for the current table to the list\n",
    "            schemas_info.append(schema_info)\n",
    "\n",
    "        # Return the schema information for all tables\n",
    "        return schemas_info\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []  # Return an empty list in case of an error\n",
    "\n",
    "schema = get_schemas(['olist_products_dataset',\"olist_orders_dataset\",\"olist_customers_dataset\",\"olist_order_items_dataset\"])\n",
    "\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text  # Import text for raw SQL queries\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Assuming you have an SQLAlchemy engine created\n",
    "engine = create_engine('sqlite:///lumin.db')  # Example for SQLite\n",
    "\n",
    "# Create a session factory bound to the engine\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def execute_query(query: str) -> List[Any]:\n",
    "    try:\n",
    "        # Create a new session\n",
    "        with Session() as session:  # Call Session() without any parameters\n",
    "            # Use a text() construct for the query\n",
    "            result = session.execute(text(query))  # Use text() for raw SQL\n",
    "            # If the query is a SELECT statement, fetch the results\n",
    "            if result.returns_rows:\n",
    "                return [row for row in result.fetchall()]  # Convert RowProxy to dict\n",
    "            else:\n",
    "                # For non-SELECT queries, commit the transaction and return an empty list\n",
    "                session.commit()\n",
    "                return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []  # Return an empty list in case of an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_query(\"SELECT * FROM results;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def simple_json_extraction(content):\n",
    "    # Find the JSON part\n",
    "    start = content.find('{')\n",
    "    end = content.rfind('}') + 1\n",
    "    \n",
    "    # Extract and parse the JSON\n",
    "    json_str = content[start:end]\n",
    "    parsed_json = json.loads(json_str)\n",
    "    \n",
    "    # Return the formatted JSON\n",
    "    return json.dumps(parsed_json, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse questions & get relevant tables and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def get_parse_question(state: dict) -> dict:\n",
    "\n",
    "    question = state['question']\n",
    "    schema = state['schema']\n",
    "\n",
    "    # print(schema, question)\n",
    "\n",
    "    # prompt = ChatPromptTemplate.from_messages([\n",
    "    #     (\"system\", '''\n",
    "    # You are an expert data analyst tasked with analyzing SQL databases. Your goal is to interpret user questions, understand the schema provided, and identify relevant tables and columns.\n",
    "\n",
    "    # Instructions:\n",
    "    # 1. Based on the user question and the provided database schema, identify the relevant tables and columns.\n",
    "    # 2. Set \"is_relevant\" to false if the question doesn't apply to the database or lacks sufficient information for an answer.\n",
    "    # 3. Focus on columns with meaningful nouns (like names or entities) and exclude columns with non-noun values (e.g., IDs, numerical data).\n",
    "    # 4. Return the response in the following JSON format:\n",
    "    # {{\n",
    "    #     \"is_relevant\": boolean,\n",
    "    #     \"relevant_tables\": [\n",
    "    #         {{\n",
    "    #             \"table_names\": [\"string\"],\n",
    "    #             \"columns\": [\"string\"],\n",
    "    #             \"noun_columns\": [\"string\"]\n",
    "    #         }}\n",
    "    #     ]\n",
    "    # }}\n",
    "\n",
    "    # Key Notes:\n",
    "    # - \"noun_columns\" should include only noun-based columns relevant to the question (e.g., \"Artist name\" for \"What are the top-selling artists?\")\n",
    "    # - \"noun_columns\" must **only contain valid column names** from the schema. Do not include noun-based values from the user question unless they match an actual column name in the schema.\n",
    "    # - Exclude numerical or ID columns that do not represent nouns or entities.\n",
    "    # - The values in \"noun_columns\" must match the exact format of the corresponding column names in \"columns\".\n",
    "    # - Check the schema if string is not available in it then don't include it in columns or noun_columns, EX: if question contain name as spandan than dont add spandan in columns or noun_columns as it is not a column name its a column value.\n",
    "    # '''),\n",
    "    #     (\"human\", \"===Database Schema:\\n{schema}\\n\\n===User Question:\\n{question}\\n\\nIdentify the relevant tables and columns based on the provided information:\")\n",
    "    # ])\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "You are an expert data analyst tasked with analyzing SQL databases. Your goal is to interpret user questions, understand the provided schema, and identify relevant tables and columns.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the user question and database schema to identify relevant tables and columns.\n",
    "2. Set \"is_relevant\" to false if the question is not applicable to the database or lacks sufficient information for an answer.\n",
    "3. Focus on columns with meaningful nouns (e.g., names, entities) and exclude non-noun columns (e.g., IDs, numerical data) unless specifically relevant to the question.\n",
    "4. Return the response in the following JSON format:\n",
    "{{\n",
    "  \"is_relevant\": boolean,\n",
    "  \"relevant_tables\": [\n",
    "    {{\n",
    "      \"table_name\": \"string\",\n",
    "      \"columns\": [\"string\"],\n",
    "      \"noun_columns\": [\"string\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Key Guidelines:\n",
    "- Always verify column names against the provided schema.\n",
    "- Include only existing schema column names in the \"columns\" and \"noun_columns\" lists.\n",
    "- \"noun_columns\" shouldn't include any numeric value verify the type from schema, type must be not Int, Bigint or any type of integer value .\n",
    "- Do not add query-mentioned values or entities to \"columns\" or \"noun_columns\" unless they are actual column names in the schema.\n",
    "- Ensure \"noun_columns\" contains only valid column names from the schema, matching their exact format.\n",
    "- Include in \"noun_columns\" only noun-based columns relevant to the question (e.g., \"artist_name\" for \"Who are the top-selling artists?\").\n",
    "- Exclude numerical or ID columns from \"noun_columns\" unless they represent meaningful entities.\n",
    "- If a term in the query matches a likely column value rather than a column name (e.g., \"Brazil\" in \"matches where Brazil scored\"), do not include it in the lists.\n",
    "\n",
    "Example:\n",
    "Question: \"What is the total number of matches where the Brazil team scored more than 2 goals?\"\n",
    "- Do not include \"Brazil team\" in columns or noun_columns as it's likely a value, not a column name.\n",
    "- Include relevant columns like \"team_name\", \"goals_scored\" if they exist in the schema.\n",
    "\n",
    "    '''),\n",
    "        (\"human\", \"===Database Schema:\\n{schema}\\n\\n===User Question:\\n{question}\\n\\nIdentify the relevant tables and columns based on the provided information:\")\n",
    "    ])\n",
    "\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "    # Use the format method to create the formatted prompt\n",
    "    formatted_prompt = prompt.format(schema=schema, question=question)\n",
    "    \n",
    "    # Invoke the LLM with the formatted prompt\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    \n",
    "    extracted_json = simple_json_extraction(response.content)\n",
    "    parsed_response = output_parser.parse(extracted_json)\n",
    "    return {\"parsed_question\": parsed_response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parsed_question': {'is_relevant': True, 'relevant_tables': [{'table_name': 'olist_order_items_dataset', 'columns': ['order_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value'], 'noun_columns': ['product_id']}, {'table_name': 'olist_products_dataset', 'columns': ['product_id', 'product_category_name'], 'noun_columns': ['product_category_name']}]}}\n"
     ]
    }
   ],
   "source": [
    "# parse_question = get_parse_question({\"schema\":schema,\"question\":\"What is the total number of matches where the Brazil team scored more than 2 goals?\"})\n",
    "parse_question = get_parse_question({\"schema\":schema,\"question\":\"Which product categories generate the most revenue?\"})\n",
    "print(parse_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parsed_question': {'is_relevant': True,\n",
       "  'relevant_tables': [{'table_name': 'olist_order_items_dataset',\n",
       "    'columns': ['order_id',\n",
       "     'product_id',\n",
       "     'seller_id',\n",
       "     'shipping_limit_date',\n",
       "     'price',\n",
       "     'freight_value'],\n",
       "    'noun_columns': ['product_id']},\n",
       "   {'table_name': 'olist_products_dataset',\n",
       "    'columns': ['product_id', 'product_category_name'],\n",
       "    'noun_columns': ['product_category_name']}]}}"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_nouns(state: dict) -> dict:\n",
    "    \"\"\"Find unique nouns in relevant tables and columns.\"\"\"\n",
    "    # Extract parsed question details from the state\n",
    "    parsed_question = state['parsed_question']\n",
    "    \n",
    "    # Return an empty dictionary if the question is not relevant\n",
    "    if not parsed_question['is_relevant']:\n",
    "        return {\"unique_nouns\": {}}\n",
    "\n",
    "    # Initialize a dictionary to collect unique nouns segregated by table and column\n",
    "    unique_nouns = {}\n",
    "\n",
    "    # Loop through the relevant tables extracted from the parsed question\n",
    "    for table_info in parsed_question['relevant_tables']:\n",
    "        table_name = table_info['table_name']\n",
    "        noun_columns = table_info['noun_columns']\n",
    "        \n",
    "        # Initialize a dictionary for the current table\n",
    "        unique_nouns[table_name] = {}\n",
    "\n",
    "        # If there are noun columns to process\n",
    "        for column in noun_columns:\n",
    "            # Construct the SQL query to select distinct values from the column\n",
    "            query = f\"SELECT DISTINCT `{column}` FROM `{table_name}`\"\n",
    "            \n",
    "            with Session() as session:           \n",
    "                result = session.execute(text(query))  # Use text() for raw SQL\n",
    "                # If the query is a SELECT statement, fetch the results\n",
    "                if result.returns_rows:\n",
    "                    # Create a set for unique values for the current column\n",
    "                    unique_values = set()\n",
    "                    for row in result:\n",
    "                        # Add each non-null value as a string to the unique values set\n",
    "                        if row[0]:  # row[0] is the value of the column\n",
    "                            unique_values.add(str(row[0]))\n",
    "\n",
    "                    # Store the unique values in the dictionary under the respective table and column\n",
    "                    unique_nouns[table_name][column] = unique_values\n",
    "\n",
    "                else:\n",
    "                    # For non-SELECT queries, commit the transaction\n",
    "                    session.commit()\n",
    "\n",
    "    # Return the unique nouns segregated by table and column\n",
    "    return {\"unique_nouns\": unique_nouns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nouns = get_unique_nouns(parse_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''\n",
    "    You are an AI assistant that generates SQL queries based on user questions, database schema, and unique nouns found in the relevant tables. Your goal is to generate valid SQL queries that can directly answer the user's question.\n",
    "\n",
    "    ### Instructions:\n",
    "    1. Parse the user question, identify relevant tables and columns from the schema, and generate an SQL query using the correct table and column names.\n",
    "    2. Ensure the SQL query answers the question using only two or three columns in the result.\n",
    "    3. If there isn't enough information to generate a query, return \"NOT_ENOUGH_INFO\".\n",
    "    4. Always enclose table and column names in backticks (`) for SQL syntax consistency.\n",
    "    5. Skip rows where any column is NULL, empty (\"\"), or contains \"N/A\".\n",
    "    6. Use the exact spellings of nouns from the unique nouns list, but only include nouns that match actual column names in the schema.\n",
    "\n",
    "    Here are some examples:\n",
    "\n",
    "    1. **What is the top selling product?**\n",
    "       **Type**: Simple Aggregation  \n",
    "       **Answer**: \n",
    "       ```sql\n",
    "       SELECT `product_name`, SUM(`quantity`) AS `total_quantity`\n",
    "       FROM `sales`\n",
    "       WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "       AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "       AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "       GROUP BY `product_name` \n",
    "       ORDER BY `total_quantity` DESC \n",
    "       LIMIT 1```\n",
    "         \n",
    "    2. **What is the total revenue for each product?**\n",
    "       **Type**: Revenue Calculation\n",
    "       **Answer**: \n",
    "       ```sql\n",
    "         SELECT `product_name`, SUM(`quantity` * `price`) AS `total_revenue`\n",
    "         FROM `sales`\n",
    "         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "         AND `price` IS NOT NULL AND `product_name` != \"\" \n",
    "         AND `quantity` != \"\" AND `price` != \"\" \n",
    "         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \n",
    "         AND `price` != \"N/A\"\n",
    "         GROUP BY `product_name`\n",
    "         ORDER BY `total_revenue` DESC\n",
    "         ```\n",
    "\n",
    "    3. **What is the market share of each product?** \n",
    "       **Type**: Market Share Calculation\n",
    "       **Answer**:\n",
    "       ```sql\n",
    "         SELECT `product_name`, \n",
    "         SUM(`quantity`) * 100.0 / (SELECT SUM(`quantity`) FROM `sales`) AS `market_share`\n",
    "         FROM `sales`\n",
    "         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \n",
    "         AND `product_name` != \"\" AND `quantity` != \"\" \n",
    "         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\"\n",
    "         GROUP BY `product_name`\n",
    "         ORDER BY `market_share` DESC\n",
    "         ```\n",
    "    4. **Which customers purchased the top-selling products?** \n",
    "       **Type**: Join Query\n",
    "       **Answer**:\n",
    "        ```sql\n",
    "         SELECT `customers`.`customer_name`, `sales`.`product_name`, `sales`.`total_quantity`\n",
    "         FROM `customers`\n",
    "         JOIN `sales` ON `customers`.`customer_id` = `sales`.`customer_id`\n",
    "         WHERE `sales`.`total_quantity` = (\n",
    "             SELECT MAX(`total_quantity`) FROM `sales`\n",
    "         )\n",
    "        ```\n",
    "\n",
    "    5. **Plot the distribution of income over time.**\n",
    "       **Type**: Distribution Plot\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT `income`, COUNT(*) AS `count`\n",
    "         FROM `users`\n",
    "         WHERE `income` IS NOT NULL AND `income` != \"\" AND `income` != \"N/A\"\n",
    "         GROUP BY `income`\n",
    "        ```\n",
    "\n",
    "    6. **What is the total sales between 2021 and 2023?**\n",
    "       **Type**: Date Range Query\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT SUM(`quantity` * `price`) AS `total_sales`\n",
    "         FROM `sales`\n",
    "         WHERE `sale_date` BETWEEN '2021-01-01' AND '2023-12-31'\n",
    "         ```\n",
    "    7. **Find the total sales for each region, including customer count**\n",
    "       **Type**: Complex Aggregation\n",
    "       **Answer**:\n",
    "         ```sql\n",
    "         SELECT `regions`.`region_name`, SUM(`sales`.`quantity` * `sales`.`price`) AS `total_sales`, COUNT(DISTINCT `customers`.`customer_id`) AS `customer_count`\n",
    "         FROM `sales`\n",
    "         JOIN `customers` ON `sales`.`customer_id` = `customers`.`customer_id`\n",
    "         JOIN `regions` ON `customers`.`region_id` = `regions`.`region_id`\n",
    "         GROUP BY `regions`.`region_name`\n",
    "         ORDER BY `total_sales` DESC\n",
    "         ```\n",
    "         \n",
    "    ### Format for Results:\n",
    "    - For simple queries (without labels): `[[x, y]]`\n",
    "    - For queries with labels: `[[label, x, y]]`\n",
    "\n",
    "    Just return the SQL query string based on the schema, question, and unique nouns provided.\n",
    "    '''), \n",
    "    (\"human\", '''===Database schema: {schema}\n",
    "\n",
    "    ===User question: {question}\n",
    "\n",
    "    ===Relevant tables and columns: {relevant_table_column}\n",
    "      \n",
    "\n",
    "    Generate SQL query string:''')\n",
    "])\n",
    "\n",
    "    # ===Unique nouns in relevant tables: {unique_nouns}\n",
    "    # This is the unique_noun format dont get confused with it :\n",
    "    #   {\n",
    "    #     \"unique_nouns\": {\n",
    "    #         \"table_name\": {\n",
    "    #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "    #             ...\n",
    "    #         },\n",
    "    #           \"table_name\": {\n",
    "    #             \"column_name\": {\"noun1\", \"noun2\",...},\n",
    "    #             ...\n",
    "    #         },\n",
    "    #          ...\n",
    "    #     }\n",
    "    # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which product categories generate the most revenue?\"\n",
    "formatted_prompt = prompt.format(schema=schema, question=question, relevant_table_column=parse_question, unique_nouns=unique_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: \\n    You are an AI assistant that generates SQL queries based on user questions, database schema, and unique nouns found in the relevant tables. Your goal is to generate valid SQL queries that can directly answer the user\\'s question.\\n\\n    ### Instructions:\\n    1. Parse the user question, identify relevant tables and columns from the schema, and generate an SQL query using the correct table and column names.\\n    2. Ensure the SQL query answers the question using only two or three columns in the result.\\n    3. If there isn\\'t enough information to generate a query, return \"NOT_ENOUGH_INFO\".\\n    4. Always enclose table and column names in backticks (`) for SQL syntax consistency.\\n    5. Skip rows where any column is NULL, empty (\"\"), or contains \"N/A\".\\n    6. Use the exact spellings of nouns from the unique nouns list, but only include nouns that match actual column names in the schema.\\n\\n    Here are some examples:\\n\\n    1. **What is the top selling product?**\\n       **Type**: Simple Aggregation  \\n       **Answer**: \\n       ```sql\\n       SELECT `product_name`, SUM(`quantity`) AS `total_quantity`\\n       FROM `sales`\\n       WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n       AND `product_name` != \"\" AND `quantity` != \"\" \\n       AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \\n       GROUP BY `product_name` \\n       ORDER BY `total_quantity` DESC \\n       LIMIT 1```\\n         \\n    2. **What is the total revenue for each product?**\\n       **Type**: Revenue Calculation\\n       **Answer**: \\n       ```sql\\n         SELECT `product_name`, SUM(`quantity` * `price`) AS `total_revenue`\\n         FROM `sales`\\n         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n         AND `price` IS NOT NULL AND `product_name` != \"\" \\n         AND `quantity` != \"\" AND `price` != \"\" \\n         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\" \\n         AND `price` != \"N/A\"\\n         GROUP BY `product_name`\\n         ORDER BY `total_revenue` DESC\\n         ```\\n\\n    3. **What is the market share of each product?** \\n       **Type**: Market Share Calculation\\n       **Answer**:\\n       ```sql\\n         SELECT `product_name`, \\n         SUM(`quantity`) * 100.0 / (SELECT SUM(`quantity`) FROM `sales`) AS `market_share`\\n         FROM `sales`\\n         WHERE `product_name` IS NOT NULL AND `quantity` IS NOT NULL \\n         AND `product_name` != \"\" AND `quantity` != \"\" \\n         AND `product_name` != \"N/A\" AND `quantity` != \"N/A\"\\n         GROUP BY `product_name`\\n         ORDER BY `market_share` DESC\\n         ```\\n    4. **Which customers purchased the top-selling products?** \\n       **Type**: Join Query\\n       **Answer**:\\n        ```sql\\n         SELECT `customers`.`customer_name`, `sales`.`product_name`, `sales`.`total_quantity`\\n         FROM `customers`\\n         JOIN `sales` ON `customers`.`customer_id` = `sales`.`customer_id`\\n         WHERE `sales`.`total_quantity` = (\\n             SELECT MAX(`total_quantity`) FROM `sales`\\n         )\\n        ```\\n\\n    5. **Plot the distribution of income over time.**\\n       **Type**: Distribution Plot\\n       **Answer**:\\n         ```sql\\n         SELECT `income`, COUNT(*) AS `count`\\n         FROM `users`\\n         WHERE `income` IS NOT NULL AND `income` != \"\" AND `income` != \"N/A\"\\n         GROUP BY `income`\\n        ```\\n\\n    6. **What is the total sales between 2021 and 2023?**\\n       **Type**: Date Range Query\\n       **Answer**:\\n         ```sql\\n         SELECT SUM(`quantity` * `price`) AS `total_sales`\\n         FROM `sales`\\n         WHERE `sale_date` BETWEEN \\'2021-01-01\\' AND \\'2023-12-31\\'\\n         ```\\n    7. **Find the total sales for each region, including customer count**\\n       **Type**: Complex Aggregation\\n       **Answer**:\\n         ```sql\\n         SELECT `regions`.`region_name`, SUM(`sales`.`quantity` * `sales`.`price`) AS `total_sales`, COUNT(DISTINCT `customers`.`customer_id`) AS `customer_count`\\n         FROM `sales`\\n         JOIN `customers` ON `sales`.`customer_id` = `customers`.`customer_id`\\n         JOIN `regions` ON `customers`.`region_id` = `regions`.`region_id`\\n         GROUP BY `regions`.`region_name`\\n         ORDER BY `total_sales` DESC\\n         ```\\n         \\n    ### Format for Results:\\n    - For simple queries (without labels): `[[x, y]]`\\n    - For queries with labels: `[[label, x, y]]`\\n\\n    Just return the SQL query string based on the schema, question, and unique nouns provided.\\n    \\nHuman: ===Database schema: [{\\'table_name\\': \\'olist_products_dataset\\', \\'schema\\': [{\\'name\\': \\'product_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'product_category_name\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'product_name_lenght\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_description_lenght\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_photos_qty\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_weight_g\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_length_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_height_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'product_width_cm\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_orders_dataset\\', \\'schema\\': [{\\'name\\': \\'order_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_status\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_purchase_timestamp\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_approved_at\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_delivered_carrier_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_delivered_customer_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_estimated_delivery_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_customers_dataset\\', \\'schema\\': [{\\'name\\': \\'customer_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_unique_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_zip_code_prefix\\', \\'type\\': \\'BIGINT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_city\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'customer_state\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}]}, {\\'table_name\\': \\'olist_order_items_dataset\\', \\'schema\\': [{\\'name\\': \\'order_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'order_item_id\\', \\'type\\': \\'BIGINT\\', \\'nullable\\': True}, {\\'name\\': \\'product_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'seller_id\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'shipping_limit_date\\', \\'type\\': \\'TEXT\\', \\'nullable\\': True}, {\\'name\\': \\'price\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}, {\\'name\\': \\'freight_value\\', \\'type\\': \\'FLOAT\\', \\'nullable\\': True}]}]\\n\\n    ===User question: Which product categories generate the most revenue?\\n\\n    ===Relevant tables and columns: {\\'parsed_question\\': {\\'is_relevant\\': True, \\'relevant_tables\\': [{\\'table_name\\': \\'olist_order_items_dataset\\', \\'columns\\': [\\'order_id\\', \\'product_id\\', \\'seller_id\\', \\'shipping_limit_date\\', \\'price\\', \\'freight_value\\'], \\'noun_columns\\': [\\'product_id\\']}, {\\'table_name\\': \\'olist_products_dataset\\', \\'columns\\': [\\'product_id\\', \\'product_category_name\\'], \\'noun_columns\\': [\\'product_category_name\\']}]}}\\n      \\n\\n    Generate SQL query string:'"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generete_sql_query():\n",
    "\n",
    "    # output_parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "    # extracted_json = simple_json_extraction(response.content)\n",
    "    # parsed_response = output_parser.parse(extracted_json)\n",
    "    response = chain.invoke({\"schema\":schema, \"question\":question, \"relevant_table_column\":parse_question})\n",
    "    # print(response)\n",
    "    clean_sql_query = response.strip('`').replace('sql\\n', '', 1).strip()\n",
    "    if response.strip() == \"NOT_ENOUGH_INFO\":\n",
    "        return {\"sql_query\": \"NOT_RELEVANT\"}\n",
    "    else:\n",
    "        return {\"sql_query\": clean_sql_query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql_que = generete_sql_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate SQL Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_fix_sql(state: dict) -> dict:\n",
    "    \"\"\"Validate and fix the generated SQL query.\"\"\"\n",
    "    sql_query = state['sql_query']\n",
    "    if sql_query == \"NOT_RELEVANT\":\n",
    "        return {\"sql_query\": \"NOT_RELEVANT\", \"sql_valid\": False}\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant that validates and fixes SQL queries. Your task is to:\n",
    "    1. Check if the SQL query is valid.\n",
    "    2. Ensure all table and column names are correctly spelled and exist in the schema. All table and column names should be enclosed in backticks, especially if they contain spaces or special characters.\n",
    "    3. Ensure the SQL query follows proper syntax (e.g., `JOIN`, `WHERE`, and other clauses are used correctly).\n",
    "    4. Take into account case sensitivity based on the schema.\n",
    "    5. If there are any issues, fix them and provide the corrected SQL query.\n",
    "    6. If no issues are found, return the original query.\n",
    "\n",
    "    Respond in JSON format with the following structure. Only respond with the JSON:\n",
    "    {{\n",
    "        \"valid\": boolean,\n",
    "        \"issues\": string or null,\n",
    "        \"corrected_query\": string\n",
    "    }}\n",
    "    '''),\n",
    "        (\"human\", '''===Database schema:\n",
    "    {schema}\n",
    "\n",
    "    ===Generated SQL query:\n",
    "    {sql_query}\n",
    "\n",
    "    Respond in JSON format with the following structure. Only respond with the JSON:\n",
    "    {{\n",
    "        \"valid\": boolean,\n",
    "        \"issues\": string or null,\n",
    "        \"corrected_query\": string\n",
    "    }}\n",
    "\n",
    "    For example:\n",
    "    1. {{\n",
    "        \"valid\": true,\n",
    "        \"issues\": null,\n",
    "        \"corrected_query\": \"None\"\n",
    "    }}\n",
    "                \n",
    "    2. {{\n",
    "        \"valid\": false,\n",
    "        \"issues\": \"Column USERS does not exist\",\n",
    "        \"corrected_query\": \"SELECT * FROM \\`users\\` WHERE age > 25\"\n",
    "    }}\n",
    "\n",
    "    3. {{\n",
    "        \"valid\": false,\n",
    "        \"issues\": \"Column names and table names should be enclosed in backticks if they contain spaces or special characters\",\n",
    "        \"corrected_query\": \"SELECT * FROM \\`gross income\\` WHERE \\`age\\` > 25\"\n",
    "    }}\n",
    "                \n",
    "    '''),\n",
    "    ])\n",
    "\n",
    "    # prompt.format(schema=schema, sql_query=sql_query)\n",
    "    output_parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    result = chain.invoke({\"schema\":schema, \"sql_query\":sql_query})\n",
    "    \n",
    "    if result[\"valid\"] and result[\"issues\"] is None:\n",
    "        return {\"sql_query\": sql_query, \"sql_valid\": True}\n",
    "    else:\n",
    "        return {\n",
    "            \"sql_query\": result[\"corrected_query\"],\n",
    "            \"sql_valid\": result[\"valid\"],\n",
    "            \"sql_issues\": result[\"issues\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sql_query = validate_and_fix_sql(generated_sql_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = execute_query(valid_sql_query[\"sql_query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get answer in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(state: dict) -> dict:\n",
    "    \"\"\"Format query results into a human-readable response.\"\"\"\n",
    "    question = state['question']\n",
    "    results = state['results']\n",
    "    if results == \"NOT_RELEVANT\":\n",
    "        return {\"answer\": \"Sorry, I can only give answers relevant to the database.\"}\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant that converts database query results into a clear, concise human-readable response. Your goal is to provide a brief conclusion to the user's question based on the query results. \n",
    "    Instructions:\n",
    "    1. Respond in one sentence.\n",
    "    2. Highlight the key result by enclosing it in double asterisks (**).\n",
    "    3. Avoid using markdown or unnecessary formatting.\n",
    "\n",
    "    '''),\n",
    "        (\"human\", \"User question: {question}\\n\\nQuery results: {results}\\n\\nConclusion:\")\n",
    "    ])\n",
    "    chain = prompt | llm | output_parser\n",
    "    response = chain.invoke({\"question\":question, \"results\":results})\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The product category that generates the most revenue is **beleza_saude**.  \\n'}"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_results({\n",
    "    \"question\":question, \n",
    "    \"results\":query_result\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format response for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_visualization(state: dict) -> dict:\n",
    "    \"\"\"Choose an appropriate visualization for the data.\"\"\"\n",
    "    question = state['question']\n",
    "    results = state['results']\n",
    "    sql_query = state['sql_query']\n",
    "\n",
    "    if results == \"NOT_RELEVANT\":\n",
    "        return {\"visualization\": \"none\", \"visualization_reasoning\": \"No visualization needed for irrelevant questions.\"}\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''\n",
    "    You are an AI assistant recommending the best data visualizations. Based on the user's question, SQL query, and query results, suggest the most suitable graph or chart type.\n",
    "\n",
    "    ### Chart Types:\n",
    "    - **Bar Graph**: For comparing categorical data or showing changes over time with more than two categories.\n",
    "    - **Horizontal Bar Graph**: For comparing few categories or when there's a large disparity between them.\n",
    "    - **Scatter Plot**: For showing relationships or distributions between two continuous numerical variables.\n",
    "    - **Pie Chart**: For displaying proportions or percentages of a whole.\n",
    "    - **Line Graph**: For showing trends over time, where both x and y axes are continuous.\n",
    "    - **None**: If no visualization is appropriate.\n",
    "\n",
    "    ### Consider These Questions:\n",
    "    1. **Aggregations**: Summarize data (e.g., average revenue by month) — Line Graph.\n",
    "    2. **Comparisons**: Compare metrics (e.g., sales of Product A vs. Product B) — Line or Bar Graph.\n",
    "    3. **Distributions**: Show data distribution (e.g., age distribution) — Scatter Plot.\n",
    "    4. **Trends Over Time**: Show changes over time (e.g., website visits) — Line Graph.\n",
    "    5. **Proportions**: Show percentages (e.g., market share) — Pie Chart.\n",
    "    6. **Correlations**: Show relationships (e.g., marketing spend vs. revenue) — Scatter Plot.\n",
    "\n",
    "    ### Format:\n",
    "         {{\n",
    "            recommended_visualization: string (bar | horizontal_bar | line | pie | scatter | none),\n",
    "            reason: Brief explanation of your recommendation\n",
    "         }}\n",
    "    '''),\n",
    "        (\"human\", '''\n",
    "    User question: {question}\n",
    "    SQL query: {sql_query}\n",
    "    Query results: {results}\n",
    "\n",
    "    Recommend a visualization:\n",
    "        '''),\n",
    "    ])\n",
    "\n",
    "    output_parser = JsonOutputParser()\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "    response = chain.invoke({\"question\":question,\"sql_query\":sql_query,\"results\":results})\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = choose_visualization({\n",
    "    \"question\":question, \n",
    "    \"results\":query_result,\n",
    "    \"sql_query\":valid_sql_query\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseFormatter(ABC):\n",
    "    def __init__(self, llm_manager):\n",
    "        self.llm = llm_manager\n",
    "\n",
    "    @abstractmethod\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        \"\"\"Formats data for visualization.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_axis_label(self, question, data, axis):\n",
    "        \"\"\"Get axis label using the LLM.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"You are a data labeling expert. Given a question and some data, provide a concise and relevant label for the {{axis}}-axis.\"),\n",
    "            (\"human\", f\"Question: {question}\\nData : {data}\\n\\nProvide a concise label for the {axis}-axis.\"),\n",
    "        ])\n",
    "        chain = prompt | llm | output_parser\n",
    "        return chain.invoke({\"question\":question, \"data\":query_result, \"axis\":\"y\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Revenue  \\n', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 1371, 'total_tokens': 1376, 'completion_time': 0.009090909, 'prompt_time': 0.0445093, 'queue_time': 0.002719674999999998, 'total_time': 0.053600209}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-47d8876f-58d2-40b2-8b7c-96772608f48c-0', usage_metadata={'input_tokens': 1371, 'output_tokens': 5, 'total_tokens': 1376})"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"You are a data labeling expert. Given a question and some data, provide a concise and relevant label for the {{axis}}-axis.\"),\n",
    "    (\"human\", f\"Question: {question}\\nData : {{data}}\\n\\nProvide a concise label for the {{axis}}-axis.\"),\n",
    "])\n",
    "chain = prompt2 | llm \n",
    "chain.invoke({\"question\":question, \"data\":query_result, \"axis\":\"y\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chart formaters\n",
    "\n",
    "class LineChartFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        x_values = [str(row[0]) for row in results]\n",
    "        y_values = [float(row[1]) for row in results]\n",
    "\n",
    "        y_axis_label = self.get_axis_label(question, results[:2], \"y\")\n",
    "        \n",
    "        return {\n",
    "            \"xValues\": x_values,\n",
    "            \"yValues\": [{\"data\": y_values, \"label\": y_axis_label.strip()}],\n",
    "        }\n",
    "\n",
    "\n",
    "class ScatterPlotFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        series = [{\"x\": float(x), \"y\": float(y), \"id\": i + 1} for i, (x, y) in enumerate(results)]\n",
    "        return {\"series\": [{\"data\": series, \"label\": \"Data Points\"}]}\n",
    "\n",
    "\n",
    "class BarChartFormatter(BaseFormatter):\n",
    "    def format(self, results: list, question: str) -> dict:\n",
    "        if isinstance(results, str):\n",
    "            results = eval(results)\n",
    "\n",
    "        labels = [str(row[0]) for row in results]\n",
    "        data = [float(row[1]) for row in results]\n",
    "        # print(\"=============Trigger==========\")\n",
    "        y_axis_label = self.get_axis_label(question, results[:2], \"y\")\n",
    "\n",
    "        return {\n",
    "            \"labels\": labels,\n",
    "            \"values\": [{\"data\": data, \"label\": y_axis_label.strip()}]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FormatterRegistry:\n",
    "    def __init__(self, llm_manager):\n",
    "        self.formatters = {\n",
    "            \"line\": LineChartFormatter(llm_manager),\n",
    "            \"scatter\": ScatterPlotFormatter(llm_manager),\n",
    "            \"bar\": BarChartFormatter(llm_manager),\n",
    "            # Add other visualizers like \"horizontal_bar\", \"pie\", etc.\n",
    "        }\n",
    "\n",
    "    def get_formatter(self, visualization):\n",
    "        return self.formatters.get(visualization, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFormatter:\n",
    "    def __init__(self):\n",
    "        self.llm_manager = llm\n",
    "        self.registry = FormatterRegistry(self.llm_manager)\n",
    "\n",
    "    def format_data_for_visualization(self, state: dict) -> dict:\n",
    "        \"\"\"Main method to format data for visualization.\"\"\"\n",
    "        visualization = state['visualization']\n",
    "        results = state['results']\n",
    "        question = state['question']\n",
    "\n",
    "        formatter = self.registry.get_formatter(visualization)\n",
    "\n",
    "        if formatter is not None:\n",
    "            try:\n",
    "                return {\"formatted_data_for_visualization\": formatter.format(results, question)}\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "        \n",
    "        return {\"formatted_data_for_visualization\": None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n"
     ]
    }
   ],
   "source": [
    "print(visualization[\"recommended_visualization\"])\n",
    "visualization_data = DataFormatter().format_data_for_visualization({\n",
    "    \"visualization\": visualization[\"recommended_visualization\"], \n",
    "    \"results\": query_result, \n",
    "    \"question\": question\n",
    "    })\n",
    "# visualization_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formatted_data_for_visualization': {'labels': ['beleza_saude', 'relogios_presentes', 'cama_mesa_banho', 'esporte_lazer', 'informatica_acessorios', 'moveis_decoracao', 'cool_stuff', 'utilidades_domesticas', 'automotivo', 'ferramentas_jardim', 'brinquedos', 'bebes', 'perfumaria', 'telefonia', 'moveis_escritorio', 'papelaria', 'pcs', 'pet_shop', 'instrumentos_musicais', 'eletroportateis', 'eletronicos', 'consoles_games', 'fashion_bolsas_e_acessorios', 'construcao_ferramentas_construcao', 'malas_acessorios', 'eletrodomesticos_2', 'casa_construcao', 'eletrodomesticos', 'agro_industria_e_comercio', 'moveis_sala', 'telefonia_fixa', 'casa_conforto', 'climatizacao', 'audio', 'portateis_casa_forno_e_cafe', 'livros_interesse_geral', 'moveis_cozinha_area_de_servico_jantar_e_jardim', 'construcao_ferramentas_iluminacao', 'construcao_ferramentas_seguranca', 'industria_comercio_e_negocios', 'alimentos', 'market_place', 'construcao_ferramentas_jardim', 'artes', 'fashion_calcados', 'bebidas', 'sinalizacao_e_seguranca', 'moveis_quarto', 'livros_tecnicos', 'construcao_ferramentas_ferramentas', 'alimentos_bebidas', 'fashion_roupa_masculina', 'fashion_underwear_e_moda_praia', 'artigos_de_natal', 'tablets_impressao_imagem', 'cine_foto', 'musica', 'dvds_blu_ray', 'livros_importados', 'artigos_de_festas', 'moveis_colchao_e_estofado', 'portateis_cozinha_e_preparadores_de_alimentos', 'fashion_roupa_feminina', 'fashion_esporte', 'la_cuisine', 'artes_e_artesanato', 'fraldas_higiene', 'pc_gamer', 'flores', 'casa_conforto_2', 'cds_dvds_musicais', 'fashion_roupa_infanto_juvenil', 'seguros_e_servicos'], 'values': [{'data': [1258681.34, 1205005.68, 1036988.68, 988048.97, 911954.32, 729762.49, 635290.85, 632248.66, 592720.11, 485256.46, 483946.6, 411764.89, 399124.87, 323667.52999999997, 273960.7, 230943.23, 222963.13, 214315.41, 191498.88, 190648.58, 160246.74, 157465.22, 152823.54, 144677.59, 140429.98, 113317.74, 83088.12, 80171.53, 72530.47, 68916.56, 59583.0, 58572.04, 55024.96, 50688.5, 47445.71, 46856.88, 46328.37, 41080.0, 40544.52, 39669.61, 29393.41, 28378.47, 25715.89, 24202.64, 23562.77, 22428.7, 21509.23, 20028.78, 19096.06, 15903.95, 15179.48, 10797.82, 9541.55, 8800.82, 7528.41, 6933.46, 6034.35, 5999.39, 4639.85, 4485.18, 4368.08, 3968.5299999999997, 2803.64, 2119.51, 2054.99, 1814.01, 1567.59, 1545.95, 1110.04, 760.27, 730.0, 569.85, 283.28999999999996], 'label': 'Revenue'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(visualization_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
